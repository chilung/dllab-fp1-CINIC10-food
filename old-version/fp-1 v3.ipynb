{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Check devices..\n",
      "Current device:  cuda\n",
      "Our selected device:  0\n",
      "1  GPUs is available\n"
     ]
    }
   ],
   "source": [
    "#To determine if your system supports CUDA\n",
    "print(\"==> Check devices..\")\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:    \n",
    "    device = 'cpu'\n",
    "print(\"Current device: \",device)\n",
    "if device == 'cuda':\n",
    "    print(\"Our selected device: \", torch.cuda.current_device())\n",
    "    print(torch.cuda.device_count(), \" GPUs is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:, i, :, :].mean()\n",
    "            std[i] += inputs[:, i, :, :].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mean_std = False\n",
    "\n",
    "if calculate_mean_std == True:\n",
    "    #we will calculate mean and std\n",
    "    #The transform function for train data\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    #The transform function for test data\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.ImageFolder(root='../data/cinic10/train', transform=transform_train)\n",
    "    valset = torchvision.datasets.ImageFolder(root='../data/cinic10/valid', transform=transform_val)\n",
    "    testset = torchvision.datasets.ImageFolder(root='../data/cinic10/test', transform=transform_test)\n",
    "\n",
    "    train_mean, train_std = get_mean_and_std(trainset)\n",
    "    print(train_mean, train_std)\n",
    "    val_mean, val_std = get_mean_and_std(valset)\n",
    "    print(val_mean, val_std)\n",
    "    test_mean, test_std = get_mean_and_std(testset)\n",
    "    print(test_mean, test_std)\n",
    "else:\n",
    "    train_mean, train_std = ([0.4770, 0.4667, 0.4244]), ([0.1884, 0.1852, 0.1874])\n",
    "    val_mean, val_std = ([0.4769, 0.4663, 0.4240]), ([0.1885, 0.1850, 0.1872])\n",
    "    test_mean, test_std = ([0.4769, 0.4668, 0.4245]), ([0.1886, 0.1851, 0.1874])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The transform function for train data\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation((-180,180)),\n",
    "    transforms.RandomAffine(degrees=(-30,30), shear=(-20,20)),\n",
    "    #transforms.Resize(256),\n",
    "    #transforms.CenterCrop(224),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "#The transform function for validation data\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(val_mean, val_std)\n",
    "])\n",
    "\n",
    "#The transform function for test data\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(test_mean, test_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.ImageFolder(root='../data/cinic10/train', transform=transform_train)\n",
    "valset = torchvision.datasets.ImageFolder(root='../data/cinic10/valid', transform=transform_val)\n",
    "testset = torchvision.datasets.ImageFolder(root='../data/cinic10/test', transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "    shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=32,\n",
    "    shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "    shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "if device == 'cuda':\n",
    "    model = model.cuda(0)\n",
    "else:\n",
    "    model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimization algorithm\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n"
     ]
    }
   ],
   "source": [
    "for phase in ['train', 'val']:\n",
    "    if phase == 'train':\n",
    "        print(phase)    \n",
    "    else:\n",
    "        print(phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "[1,   200]\n",
      "[1,   400]\n",
      "[1,   600]\n",
      "[1,   800]\n",
      "[1,  1000]\n",
      "[1,  1200]\n",
      "[1,  1400]\n",
      "[1,  1600]\n",
      "[1,  1800]\n",
      "[1,  2000]\n",
      "[1,  2200]\n",
      "[1,  2400]\n",
      "[1,  2600]\n",
      "[1,  2800]\n",
      "0 Epoch train Loss: 0.0612 Acc: 0.2736\n",
      "[1,   200]\n",
      "[1,   400]\n",
      "[1,   600]\n",
      "[1,   800]\n",
      "[1,  1000]\n",
      "[1,  1200]\n",
      "[1,  1400]\n",
      "[1,  1600]\n",
      "[1,  1800]\n",
      "[1,  2000]\n",
      "[1,  2200]\n",
      "[1,  2400]\n",
      "[1,  2600]\n",
      "[1,  2800]\n",
      "0 Epoch val Loss: 0.0567 Acc: 0.3306\n",
      "[2,   200]\n",
      "[2,   400]\n",
      "[2,   600]\n",
      "[2,   800]\n",
      "[2,  1000]\n",
      "[2,  1200]\n",
      "[2,  1400]\n",
      "[2,  1600]\n",
      "[2,  1800]\n",
      "[2,  2000]\n",
      "[2,  2200]\n",
      "[2,  2400]\n",
      "[2,  2600]\n",
      "[2,  2800]\n",
      "1 Epoch train Loss: 0.0580 Acc: 0.3151\n",
      "[2,   200]\n",
      "[2,   400]\n",
      "[2,   600]\n",
      "[2,   800]\n",
      "[2,  1000]\n",
      "[2,  1200]\n",
      "[2,  1400]\n",
      "[2,  1600]\n",
      "[2,  1800]\n",
      "[2,  2000]\n",
      "[2,  2200]\n",
      "[2,  2400]\n",
      "[2,  2600]\n",
      "[2,  2800]\n",
      "1 Epoch val Loss: 0.0561 Acc: 0.3391\n",
      "[3,   200]\n",
      "[3,   400]\n",
      "[3,   600]\n",
      "[3,   800]\n",
      "[3,  1000]\n",
      "[3,  1200]\n",
      "[3,  1400]\n",
      "[3,  1600]\n",
      "[3,  1800]\n",
      "[3,  2000]\n",
      "[3,  2200]\n",
      "[3,  2400]\n",
      "[3,  2600]\n",
      "[3,  2800]\n",
      "2 Epoch train Loss: 0.0565 Acc: 0.3349\n",
      "[3,   200]\n",
      "[3,   400]\n",
      "[3,   600]\n",
      "[3,   800]\n",
      "[3,  1000]\n",
      "[3,  1200]\n",
      "[3,  1400]\n",
      "[3,  1600]\n",
      "[3,  1800]\n",
      "[3,  2000]\n",
      "[3,  2200]\n",
      "[3,  2400]\n",
      "[3,  2600]\n",
      "[3,  2800]\n",
      "2 Epoch val Loss: 0.0528 Acc: 0.3813\n",
      "[4,   200]\n",
      "[4,   400]\n",
      "[4,   600]\n",
      "[4,   800]\n",
      "[4,  1000]\n",
      "[4,  1200]\n",
      "[4,  1400]\n",
      "[4,  1600]\n",
      "[4,  1800]\n",
      "[4,  2000]\n",
      "[4,  2200]\n",
      "[4,  2400]\n",
      "[4,  2600]\n",
      "[4,  2800]\n",
      "3 Epoch train Loss: 0.0554 Acc: 0.3508\n",
      "[4,   200]\n",
      "[4,   400]\n",
      "[4,   600]\n",
      "[4,   800]\n",
      "[4,  1000]\n",
      "[4,  1200]\n",
      "[4,  1400]\n",
      "[4,  1600]\n",
      "[4,  1800]\n",
      "[4,  2000]\n",
      "[4,  2200]\n",
      "[4,  2400]\n",
      "[4,  2600]\n",
      "[4,  2800]\n",
      "3 Epoch val Loss: 0.0517 Acc: 0.3988\n",
      "[5,   200]\n",
      "[5,   400]\n",
      "[5,   600]\n",
      "[5,   800]\n",
      "[5,  1000]\n",
      "[5,  1200]\n",
      "[5,  1400]\n",
      "[5,  1600]\n",
      "[5,  1800]\n",
      "[5,  2000]\n",
      "[5,  2200]\n",
      "[5,  2400]\n",
      "[5,  2600]\n",
      "[5,  2800]\n",
      "4 Epoch train Loss: 0.0541 Acc: 0.3674\n",
      "[5,   200]\n",
      "[5,   400]\n",
      "[5,   600]\n",
      "[5,   800]\n",
      "[5,  1000]\n",
      "[5,  1200]\n",
      "[5,  1400]\n",
      "[5,  1600]\n",
      "[5,  1800]\n",
      "[5,  2000]\n",
      "[5,  2200]\n",
      "[5,  2400]\n",
      "[5,  2600]\n",
      "[5,  2800]\n",
      "4 Epoch val Loss: 0.0492 Acc: 0.4296\n",
      "[6,   200]\n",
      "[6,   400]\n",
      "[6,   600]\n",
      "[6,   800]\n",
      "[6,  1000]\n",
      "[6,  1200]\n",
      "[6,  1400]\n",
      "[6,  1600]\n",
      "[6,  1800]\n",
      "[6,  2000]\n",
      "[6,  2200]\n",
      "[6,  2400]\n",
      "[6,  2600]\n",
      "[6,  2800]\n",
      "5 Epoch train Loss: 0.0531 Acc: 0.3809\n",
      "[6,   200]\n",
      "[6,   400]\n",
      "[6,   600]\n",
      "[6,   800]\n",
      "[6,  1000]\n",
      "[6,  1200]\n",
      "[6,  1400]\n",
      "[6,  1600]\n",
      "[6,  1800]\n",
      "[6,  2000]\n",
      "[6,  2200]\n",
      "[6,  2400]\n",
      "[6,  2600]\n",
      "[6,  2800]\n",
      "5 Epoch val Loss: 0.0530 Acc: 0.4005\n",
      "[7,   200]\n",
      "[7,   400]\n",
      "[7,   600]\n",
      "[7,   800]\n",
      "[7,  1000]\n",
      "[7,  1200]\n",
      "[7,  1400]\n",
      "[7,  1600]\n",
      "[7,  1800]\n",
      "[7,  2000]\n",
      "[7,  2200]\n",
      "[7,  2400]\n",
      "[7,  2600]\n",
      "[7,  2800]\n",
      "6 Epoch train Loss: 0.0522 Acc: 0.3931\n",
      "[7,   200]\n",
      "[7,   400]\n",
      "[7,   600]\n",
      "[7,   800]\n",
      "[7,  1000]\n",
      "[7,  1200]\n",
      "[7,  1400]\n",
      "[7,  1600]\n",
      "[7,  1800]\n",
      "[7,  2000]\n",
      "[7,  2200]\n",
      "[7,  2400]\n",
      "[7,  2600]\n",
      "[7,  2800]\n",
      "6 Epoch val Loss: 0.0495 Acc: 0.4352\n",
      "[8,   200]\n",
      "[8,   400]\n",
      "[8,   600]\n",
      "[8,   800]\n",
      "[8,  1000]\n",
      "[8,  1200]\n",
      "[8,  1400]\n",
      "[8,  1600]\n",
      "[8,  1800]\n",
      "[8,  2000]\n",
      "[8,  2200]\n",
      "[8,  2400]\n",
      "[8,  2600]\n",
      "[8,  2800]\n",
      "7 Epoch train Loss: 0.0513 Acc: 0.4046\n",
      "[8,   200]\n",
      "[8,   400]\n",
      "[8,   600]\n",
      "[8,   800]\n",
      "[8,  1000]\n",
      "[8,  1200]\n",
      "[8,  1400]\n",
      "[8,  1600]\n",
      "[8,  1800]\n",
      "[8,  2000]\n",
      "[8,  2200]\n",
      "[8,  2400]\n",
      "[8,  2600]\n",
      "[8,  2800]\n",
      "7 Epoch val Loss: 0.0465 Acc: 0.4614\n",
      "[9,   200]\n",
      "[9,   400]\n",
      "[9,   600]\n",
      "[9,   800]\n",
      "[9,  1000]\n",
      "[9,  1200]\n",
      "[9,  1400]\n",
      "[9,  1600]\n",
      "[9,  1800]\n",
      "[9,  2000]\n",
      "[9,  2200]\n",
      "[9,  2400]\n",
      "[9,  2600]\n",
      "[9,  2800]\n",
      "8 Epoch train Loss: 0.0505 Acc: 0.4137\n",
      "[9,   200]\n",
      "[9,   400]\n",
      "[9,   600]\n",
      "[9,   800]\n",
      "[9,  1000]\n",
      "[9,  1200]\n",
      "[9,  1400]\n",
      "[9,  1600]\n",
      "[9,  1800]\n",
      "[9,  2000]\n",
      "[9,  2200]\n",
      "[9,  2400]\n",
      "[9,  2600]\n",
      "[9,  2800]\n",
      "8 Epoch val Loss: 0.0466 Acc: 0.4617\n",
      "[10,   200]\n",
      "[10,   400]\n",
      "[10,   600]\n",
      "[10,   800]\n",
      "[10,  1000]\n",
      "[10,  1200]\n",
      "[10,  1400]\n",
      "[10,  1600]\n",
      "[10,  1800]\n",
      "[10,  2000]\n",
      "[10,  2200]\n",
      "[10,  2400]\n",
      "[10,  2600]\n",
      "[10,  2800]\n",
      "9 Epoch train Loss: 0.0497 Acc: 0.4245\n",
      "[10,   200]\n",
      "[10,   400]\n",
      "[10,   600]\n",
      "[10,   800]\n",
      "[10,  1000]\n",
      "[10,  1200]\n",
      "[10,  1400]\n",
      "[10,  1600]\n",
      "[10,  1800]\n",
      "[10,  2000]\n",
      "[10,  2200]\n",
      "[10,  2400]\n",
      "[10,  2600]\n",
      "[10,  2800]\n",
      "9 Epoch val Loss: 0.0458 Acc: 0.4695\n",
      "[11,   200]\n",
      "[11,   400]\n",
      "[11,   600]\n",
      "[11,   800]\n",
      "[11,  1000]\n",
      "[11,  1200]\n",
      "[11,  1400]\n",
      "[11,  1600]\n",
      "[11,  1800]\n",
      "[11,  2000]\n",
      "[11,  2200]\n",
      "[11,  2400]\n",
      "[11,  2600]\n",
      "[11,  2800]\n",
      "10 Epoch train Loss: 0.0489 Acc: 0.4308\n",
      "[11,   200]\n",
      "[11,   400]\n",
      "[11,   600]\n",
      "[11,   800]\n",
      "[11,  1000]\n",
      "[11,  1200]\n",
      "[11,  1400]\n",
      "[11,  1600]\n",
      "[11,  1800]\n",
      "[11,  2000]\n",
      "[11,  2200]\n",
      "[11,  2400]\n",
      "[11,  2600]\n",
      "[11,  2800]\n",
      "10 Epoch val Loss: 0.0441 Acc: 0.4930\n",
      "[12,   200]\n",
      "[12,   400]\n",
      "[12,   600]\n",
      "[12,   800]\n",
      "[12,  1000]\n",
      "[12,  1200]\n",
      "[12,  1400]\n",
      "[12,  1600]\n",
      "[12,  1800]\n",
      "[12,  2000]\n",
      "[12,  2200]\n",
      "[12,  2400]\n",
      "[12,  2600]\n",
      "[12,  2800]\n",
      "11 Epoch train Loss: 0.0482 Acc: 0.4419\n",
      "[12,   200]\n",
      "[12,   400]\n",
      "[12,   600]\n",
      "[12,   800]\n",
      "[12,  1000]\n",
      "[12,  1200]\n",
      "[12,  1400]\n",
      "[12,  1600]\n",
      "[12,  1800]\n",
      "[12,  2000]\n",
      "[12,  2200]\n",
      "[12,  2400]\n",
      "[12,  2600]\n",
      "[12,  2800]\n",
      "11 Epoch val Loss: 0.0461 Acc: 0.4783\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-04.\n",
      "[13,   200]\n",
      "[13,   400]\n",
      "[13,   600]\n",
      "[13,   800]\n",
      "[13,  1000]\n",
      "[13,  1200]\n",
      "[13,  1400]\n",
      "[13,  1600]\n",
      "[13,  1800]\n",
      "[13,  2000]\n",
      "[13,  2200]\n",
      "[13,  2400]\n",
      "[13,  2600]\n",
      "[13,  2800]\n",
      "12 Epoch train Loss: 0.0458 Acc: 0.4733\n",
      "[13,   200]\n",
      "[13,   400]\n",
      "[13,   600]\n",
      "[13,   800]\n",
      "[13,  1000]\n",
      "[13,  1200]\n",
      "[13,  1400]\n",
      "[13,  1600]\n",
      "[13,  1800]\n",
      "[13,  2000]\n",
      "[13,  2200]\n",
      "[13,  2400]\n",
      "[13,  2600]\n",
      "[13,  2800]\n",
      "12 Epoch val Loss: 0.0406 Acc: 0.5347\n",
      "[14,   200]\n",
      "[14,   400]\n",
      "[14,   600]\n",
      "[14,   800]\n",
      "[14,  1000]\n",
      "[14,  1200]\n",
      "[14,  1400]\n",
      "[14,  1600]\n",
      "[14,  1800]\n",
      "[14,  2000]\n",
      "[14,  2200]\n",
      "[14,  2400]\n",
      "[14,  2600]\n",
      "[14,  2800]\n",
      "13 Epoch train Loss: 0.0454 Acc: 0.4783\n",
      "[14,   200]\n",
      "[14,   400]\n",
      "[14,   600]\n",
      "[14,   800]\n",
      "[14,  1000]\n",
      "[14,  1200]\n",
      "[14,  1400]\n",
      "[14,  1600]\n",
      "[14,  1800]\n",
      "[14,  2000]\n",
      "[14,  2200]\n",
      "[14,  2400]\n",
      "[14,  2600]\n",
      "[14,  2800]\n",
      "13 Epoch val Loss: 0.0400 Acc: 0.5398\n",
      "[15,   200]\n",
      "[15,   400]\n",
      "[15,   600]\n",
      "[15,   800]\n",
      "[15,  1000]\n",
      "[15,  1200]\n",
      "[15,  1400]\n",
      "[15,  1600]\n",
      "[15,  1800]\n",
      "[15,  2000]\n",
      "[15,  2200]\n",
      "[15,  2400]\n",
      "[15,  2600]\n",
      "[15,  2800]\n",
      "14 Epoch train Loss: 0.0451 Acc: 0.4798\n",
      "[15,   200]\n",
      "[15,   400]\n",
      "[15,   600]\n",
      "[15,   800]\n",
      "[15,  1000]\n",
      "[15,  1200]\n",
      "[15,  1400]\n",
      "[15,  1600]\n",
      "[15,  1800]\n",
      "[15,  2000]\n",
      "[15,  2200]\n",
      "[15,  2400]\n",
      "[15,  2600]\n",
      "[15,  2800]\n",
      "14 Epoch val Loss: 0.0399 Acc: 0.5410\n",
      "[16,   200]\n",
      "[16,   400]\n",
      "[16,   600]\n",
      "[16,   800]\n",
      "[16,  1000]\n",
      "[16,  1200]\n",
      "[16,  1400]\n",
      "[16,  1600]\n",
      "[16,  1800]\n",
      "[16,  2000]\n",
      "[16,  2200]\n",
      "[16,  2400]\n",
      "[16,  2600]\n",
      "[16,  2800]\n",
      "15 Epoch train Loss: 0.0449 Acc: 0.4838\n",
      "[16,   200]\n",
      "[16,   400]\n",
      "[16,   600]\n",
      "[16,   800]\n",
      "[16,  1000]\n",
      "[16,  1200]\n",
      "[16,  1400]\n",
      "[16,  1600]\n",
      "[16,  1800]\n",
      "[16,  2000]\n",
      "[16,  2200]\n",
      "[16,  2400]\n",
      "[16,  2600]\n",
      "[16,  2800]\n",
      "15 Epoch val Loss: 0.0393 Acc: 0.5492\n",
      "[17,   200]\n",
      "[17,   400]\n",
      "[17,   600]\n",
      "[17,   800]\n",
      "[17,  1000]\n",
      "[17,  1200]\n",
      "[17,  1400]\n",
      "[17,  1600]\n",
      "[17,  1800]\n",
      "[17,  2000]\n",
      "[17,  2200]\n",
      "[17,  2400]\n",
      "[17,  2600]\n",
      "[17,  2800]\n",
      "16 Epoch train Loss: 0.0448 Acc: 0.4848\n",
      "[17,   200]\n",
      "[17,   400]\n",
      "[17,   600]\n",
      "[17,   800]\n",
      "[17,  1000]\n",
      "[17,  1200]\n",
      "[17,  1400]\n",
      "[17,  1600]\n",
      "[17,  1800]\n",
      "[17,  2000]\n",
      "[17,  2200]\n",
      "[17,  2400]\n",
      "[17,  2600]\n",
      "[17,  2800]\n",
      "16 Epoch val Loss: 0.0395 Acc: 0.5452\n",
      "[18,   200]\n",
      "[18,   400]\n",
      "[18,   600]\n",
      "[18,   800]\n",
      "[18,  1000]\n",
      "[18,  1200]\n",
      "[18,  1400]\n",
      "[18,  1600]\n",
      "[18,  1800]\n",
      "[18,  2000]\n",
      "[18,  2200]\n",
      "[18,  2400]\n",
      "[18,  2600]\n",
      "[18,  2800]\n",
      "17 Epoch train Loss: 0.0446 Acc: 0.4862\n",
      "[18,   200]\n",
      "[18,   400]\n",
      "[18,   600]\n",
      "[18,   800]\n",
      "[18,  1000]\n",
      "[18,  1200]\n",
      "[18,  1400]\n",
      "[18,  1600]\n",
      "[18,  1800]\n",
      "[18,  2000]\n",
      "[18,  2200]\n",
      "[18,  2400]\n",
      "[18,  2600]\n",
      "[18,  2800]\n",
      "17 Epoch val Loss: 0.0396 Acc: 0.5486\n",
      "[19,   200]\n",
      "[19,   400]\n",
      "[19,   600]\n",
      "[19,   800]\n",
      "[19,  1000]\n",
      "[19,  1200]\n",
      "[19,  1400]\n",
      "[19,  1600]\n",
      "[19,  1800]\n",
      "[19,  2000]\n",
      "[19,  2200]\n",
      "[19,  2400]\n",
      "[19,  2600]\n",
      "[19,  2800]\n",
      "18 Epoch train Loss: 0.0443 Acc: 0.4900\n",
      "[19,   200]\n",
      "[19,   400]\n",
      "[19,   600]\n",
      "[19,   800]\n",
      "[19,  1000]\n",
      "[19,  1200]\n",
      "[19,  1400]\n",
      "[19,  1600]\n",
      "[19,  1800]\n",
      "[19,  2000]\n",
      "[19,  2200]\n",
      "[19,  2400]\n",
      "[19,  2600]\n",
      "[19,  2800]\n",
      "18 Epoch val Loss: 0.0393 Acc: 0.5475\n",
      "[20,   200]\n",
      "[20,   400]\n",
      "[20,   600]\n",
      "[20,   800]\n",
      "[20,  1000]\n",
      "[20,  1200]\n",
      "[20,  1400]\n",
      "[20,  1600]\n",
      "[20,  1800]\n",
      "[20,  2000]\n",
      "[20,  2200]\n",
      "[20,  2400]\n",
      "[20,  2600]\n",
      "[20,  2800]\n",
      "19 Epoch train Loss: 0.0442 Acc: 0.4920\n",
      "[20,   200]\n",
      "[20,   400]\n",
      "[20,   600]\n",
      "[20,   800]\n",
      "[20,  1000]\n",
      "[20,  1200]\n",
      "[20,  1400]\n",
      "[20,  1600]\n",
      "[20,  1800]\n",
      "[20,  2000]\n",
      "[20,  2200]\n",
      "[20,  2400]\n",
      "[20,  2600]\n",
      "[20,  2800]\n",
      "19 Epoch val Loss: 0.0387 Acc: 0.5540\n",
      "[21,   200]\n",
      "[21,   400]\n",
      "[21,   600]\n",
      "[21,   800]\n",
      "[21,  1000]\n",
      "[21,  1200]\n",
      "[21,  1400]\n",
      "[21,  1600]\n",
      "[21,  1800]\n",
      "[21,  2000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21,  2200]\n",
      "[21,  2400]\n",
      "[21,  2600]\n",
      "[21,  2800]\n",
      "20 Epoch train Loss: 0.0440 Acc: 0.4932\n",
      "[21,   200]\n",
      "[21,   400]\n",
      "[21,   600]\n",
      "[21,   800]\n",
      "[21,  1000]\n",
      "[21,  1200]\n",
      "[21,  1400]\n",
      "[21,  1600]\n",
      "[21,  1800]\n",
      "[21,  2000]\n",
      "[21,  2200]\n",
      "[21,  2400]\n",
      "[21,  2600]\n",
      "[21,  2800]\n",
      "20 Epoch val Loss: 0.0390 Acc: 0.5516\n",
      "[22,   200]\n",
      "[22,   400]\n",
      "[22,   600]\n",
      "[22,   800]\n",
      "[22,  1000]\n",
      "[22,  1200]\n",
      "[22,  1400]\n",
      "[22,  1600]\n",
      "[22,  1800]\n",
      "[22,  2000]\n",
      "[22,  2200]\n",
      "[22,  2400]\n",
      "[22,  2600]\n",
      "[22,  2800]\n",
      "21 Epoch train Loss: 0.0439 Acc: 0.4953\n",
      "[22,   200]\n",
      "[22,   400]\n",
      "[22,   600]\n",
      "[22,   800]\n",
      "[22,  1000]\n",
      "[22,  1200]\n",
      "[22,  1400]\n",
      "[22,  1600]\n",
      "[22,  1800]\n",
      "[22,  2000]\n",
      "[22,  2200]\n",
      "[22,  2400]\n",
      "[22,  2600]\n",
      "[22,  2800]\n",
      "21 Epoch val Loss: 0.0382 Acc: 0.5610\n",
      "[23,   200]\n",
      "[23,   400]\n",
      "[23,   600]\n",
      "[23,   800]\n",
      "[23,  1000]\n",
      "[23,  1200]\n",
      "[23,  1400]\n",
      "[23,  1600]\n",
      "[23,  1800]\n",
      "[23,  2000]\n",
      "[23,  2200]\n",
      "[23,  2400]\n",
      "[23,  2600]\n",
      "[23,  2800]\n",
      "22 Epoch train Loss: 0.0437 Acc: 0.4966\n",
      "[23,   200]\n",
      "[23,   400]\n",
      "[23,   600]\n",
      "[23,   800]\n",
      "[23,  1000]\n",
      "[23,  1200]\n",
      "[23,  1400]\n",
      "[23,  1600]\n",
      "[23,  1800]\n",
      "[23,  2000]\n",
      "[23,  2200]\n",
      "[23,  2400]\n",
      "[23,  2600]\n",
      "[23,  2800]\n",
      "22 Epoch val Loss: 0.0381 Acc: 0.5634\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-05.\n",
      "[24,   200]\n",
      "[24,   400]\n",
      "[24,   600]\n",
      "[24,   800]\n",
      "[24,  1000]\n",
      "[24,  1200]\n",
      "[24,  1400]\n",
      "[24,  1600]\n",
      "[24,  1800]\n",
      "[24,  2000]\n",
      "[24,  2200]\n",
      "[24,  2400]\n",
      "[24,  2600]\n",
      "[24,  2800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-96:\n",
      "Process Process-95:\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fbcd8a0bbdb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# if the model predicts the same results as the true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# label, then the correct counter will plus 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 920, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/root/anaconda3/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/transforms/transforms.py\", line 546, in __call__\n",
      "    return F.resized_crop(img, i, j, h, w, self.size, self.interpolation)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/transforms/functional.py\", line 331, in resized_crop\n",
      "    img = resize(img, size, interpolation)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/transforms/functional.py\", line 206, in resize\n",
      "    return img.resize(size[::-1], interpolation)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/PIL/Image.py\", line 1765, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "best_model = model\n",
    "best_acc = 0.0\n",
    "val_acc = 0.0\n",
    "print(device)\n",
    "\n",
    "model.train()\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, verbose=True)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma=0.5)\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "        \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train(True)  # Set model to training mode\n",
    "            dset_loaders = trainloader\n",
    "        else:\n",
    "            model.train(False)  # Set model to evaluate mode\n",
    "            dset_loaders = valloader\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        \n",
    "        for i, data in enumerate(dset_loaders, 0):\n",
    "        \n",
    "            (inputs, labels) = data\n",
    "            \n",
    "            #change the type into cuda tensor \n",
    "            if device == 'cuda':\n",
    "                inputs = inputs.cuda(0)\n",
    "                labels = labels.cuda(0)\n",
    "            else:\n",
    "                inputs = inputs.cpu()\n",
    "                labels = labels.cpu()\n",
    "\n",
    "            #print(labels)\n",
    "            #print(inputs)\n",
    "        \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            # select the class with highest probability\n",
    "            _, pred = outputs.max(1)\n",
    "            # if the model predicts the same results as the true\n",
    "            # label, then the correct counter will plus 1\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "        \n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if (i % 200) == 199:    # print every 200 mini-batches\n",
    "                print('[%d, %5d]' % (epoch + 1, i + 1))\n",
    "            \n",
    "        if phase == 'train':\n",
    "            epoch_loss = running_loss / len(trainset)\n",
    "            epoch_acc = correct / len(trainset)\n",
    "        else:\n",
    "            epoch_loss = running_loss / len(valset)\n",
    "            epoch_acc = correct / len(valset)\n",
    "            val_acc = epoch_acc\n",
    "\n",
    "        print('{:d} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(epoch, phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(best_model, './model.pt')\n",
    "    lr_scheduler.step(val_acc)\n",
    "print('Finished Training')\n",
    "\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Saving model..\n",
      "Finished Saving\n"
     ]
    }
   ],
   "source": [
    "print('==> Saving model..')\n",
    "\n",
    "#only save model parameters\n",
    "torch.save(model.state_dict(), './checkpoint.t7')\n",
    "#you also can store some log information\n",
    "state = {\n",
    "    'net': model.state_dict(),\n",
    "    'acc': 100.*correct/len(trainset),\n",
    "    'epoch': epoch\n",
    "}\n",
    "torch.save(state, './checkpoint.t7')\n",
    "\n",
    "#save entire model\n",
    "torch.save(model, './model.pt')\n",
    "\n",
    "print('Finished Saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Testing model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('==> Testing model..')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  200]\n",
      "[  400]\n",
      "[  600]\n",
      "[  800]\n",
      "[ 1000]\n",
      "[ 1200]\n",
      "[ 1400]\n",
      "[ 1600]\n",
      "[ 1800]\n",
      "[ 2000]\n",
      "[ 2200]\n",
      "[ 2400]\n",
      "[ 2600]\n",
      "[ 2800]\n",
      "Accuracy of the network on the 90000 test images: 70.05%, and loss is: 0.036\n",
      "Accuracy of airplane : 81 %\n",
      "Accuracy of automobile : 75 %\n",
      "Accuracy of  bird : 62 %\n",
      "Accuracy of   cat : 57 %\n",
      "Accuracy of  deer : 60 %\n",
      "Accuracy of   dog : 53 %\n",
      "Accuracy of  frog : 82 %\n",
      "Accuracy of horse : 75 %\n",
      "Accuracy of  ship : 78 %\n",
      "Accuracy of truck : 73 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "running_loss = 0.0\n",
    "# device == 'cpu'\n",
    "class_correct = list(0. for i in range(11))\n",
    "class_total = list(0. for i in range(11))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mini_batch, data in enumerate(testloader, 0):\n",
    "        images, labels = data\n",
    "\n",
    "        if device == 'cuda':\n",
    "            images = images.cuda(0)\n",
    "            labels = labels.cuda(0)\n",
    "        else:\n",
    "            images = images.cpu()\n",
    "            labels = labels.cpu()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        c = (predicted == labels).squeeze()\n",
    "        #print(predicted)\n",
    "        #print(labels.size(0))\n",
    "        #print(c)\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "        if(mini_batch % 200 == 199):\n",
    "            print('[%5d]' % (mini_batch + 1))\n",
    "            \n",
    "print('Accuracy of the network on the %d test images: %.2f%%, and loss is: %.3f'\n",
    "      % (total, 100 * correct / total, running_loss / total))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
