{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Check devices..\n",
      "Current device:  cuda\n",
      "Our selected device:  0\n",
      "1  GPUs is available\n"
     ]
    }
   ],
   "source": [
    "#To determine if your system supports CUDA\n",
    "print(\"==> Check devices..\")\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:    \n",
    "    device = 'cpu'\n",
    "print(\"Current device: \",device)\n",
    "if device == 'cuda':\n",
    "    print(\"Our selected device: \", torch.cuda.current_device())\n",
    "    print(torch.cuda.device_count(), \" GPUs is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:, i, :, :].mean()\n",
    "            std[i] += inputs[:, i, :, :].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mean_std = False\n",
    "\n",
    "if calculate_mean_std == True:\n",
    "    #we will calculate mean and std\n",
    "    #The transform function for train data\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    #The transform function for test data\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.ImageFolder(root='../data/cinic10/train', transform=transform_train)\n",
    "    valset = torchvision.datasets.ImageFolder(root='../data/cinic10/valid', transform=transform_val)\n",
    "    testset = torchvision.datasets.ImageFolder(root='../data/cinic10/test', transform=transform_test)\n",
    "\n",
    "    train_mean, train_std = get_mean_and_std(trainset)\n",
    "    print(train_mean, train_std)\n",
    "    val_mean, val_std = get_mean_and_std(valset)\n",
    "    print(val_mean, val_std)\n",
    "    test_mean, test_std = get_mean_and_std(testset)\n",
    "    print(test_mean, test_std)\n",
    "else:\n",
    "    train_mean, train_std = ([0.4770, 0.4667, 0.4244]), ([0.1884, 0.1852, 0.1874])\n",
    "    val_mean, val_std = ([0.4769, 0.4663, 0.4240]), ([0.1885, 0.1850, 0.1872])\n",
    "    test_mean, test_std = ([0.4769, 0.4668, 0.4245]), ([0.1886, 0.1851, 0.1874])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The transform function for train data\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "#The transform function for validation data\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(val_mean, val_std)\n",
    "])\n",
    "\n",
    "#The transform function for test data\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(test_mean, test_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.ImageFolder(root='../data/cinic10/train', transform=transform_train)\n",
    "valset = torchvision.datasets.ImageFolder(root='../data/cinic10/valid', transform=transform_val)\n",
    "testset = torchvision.datasets.ImageFolder(root='../data/cinic10/test', transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "    shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=32,\n",
    "    shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "    shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "if device == 'cuda':\n",
    "    model = model.cuda(0)\n",
    "else:\n",
    "    model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimization algorithm\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n"
     ]
    }
   ],
   "source": [
    "for phase in ['train', 'val']:\n",
    "    if phase == 'train':\n",
    "        print(phase)    \n",
    "    else:\n",
    "        print(phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "[1,   200]\n",
      "[1,   400]\n",
      "[1,   600]\n",
      "[1,   800]\n",
      "[1,  1000]\n",
      "[1,  1200]\n",
      "[1,  1400]\n",
      "[1,  1600]\n",
      "[1,  1800]\n",
      "[1,  2000]\n",
      "[1,  2200]\n",
      "[1,  2400]\n",
      "[1,  2600]\n",
      "[1,  2800]\n",
      "0 Epoch train Loss: 0.0518 Acc: 0.3933\n",
      "[1,   200]\n",
      "[1,   400]\n",
      "[1,   600]\n",
      "[1,   800]\n",
      "[1,  1000]\n",
      "[1,  1200]\n",
      "[1,  1400]\n",
      "[1,  1600]\n",
      "[1,  1800]\n",
      "[1,  2000]\n",
      "[1,  2200]\n",
      "[1,  2400]\n",
      "[1,  2600]\n",
      "[1,  2800]\n",
      "0 Epoch val Loss: 0.0450 Acc: 0.4667\n",
      "[2,   200]\n",
      "[2,   400]\n",
      "[2,   600]\n",
      "[2,   800]\n",
      "[2,  1000]\n",
      "[2,  1200]\n",
      "[2,  1400]\n",
      "[2,  1600]\n",
      "[2,  1800]\n",
      "[2,  2000]\n",
      "[2,  2200]\n",
      "[2,  2400]\n",
      "[2,  2600]\n",
      "[2,  2800]\n",
      "1 Epoch train Loss: 0.0412 Acc: 0.5181\n",
      "[2,   200]\n",
      "[2,   400]\n",
      "[2,   600]\n",
      "[2,   800]\n",
      "[2,  1000]\n",
      "[2,  1200]\n",
      "[2,  1400]\n",
      "[2,  1600]\n",
      "[2,  1800]\n",
      "[2,  2000]\n",
      "[2,  2200]\n",
      "[2,  2400]\n",
      "[2,  2600]\n",
      "[2,  2800]\n",
      "1 Epoch val Loss: 0.0393 Acc: 0.5396\n",
      "[3,   200]\n",
      "[3,   400]\n",
      "[3,   600]\n",
      "[3,   800]\n",
      "[3,  1000]\n",
      "[3,  1200]\n",
      "[3,  1400]\n",
      "[3,  1600]\n",
      "[3,  1800]\n",
      "[3,  2000]\n",
      "[3,  2200]\n",
      "[3,  2400]\n",
      "[3,  2600]\n",
      "[3,  2800]\n",
      "2 Epoch train Loss: 0.0359 Acc: 0.5868\n",
      "[3,   200]\n",
      "[3,   400]\n",
      "[3,   600]\n",
      "[3,   800]\n",
      "[3,  1000]\n",
      "[3,  1200]\n",
      "[3,  1400]\n",
      "[3,  1600]\n",
      "[3,  1800]\n",
      "[3,  2000]\n",
      "[3,  2200]\n",
      "[3,  2400]\n",
      "[3,  2600]\n",
      "[3,  2800]\n",
      "2 Epoch val Loss: 0.0351 Acc: 0.5924\n",
      "[4,   200]\n",
      "[4,   400]\n",
      "[4,   600]\n",
      "[4,   800]\n",
      "[4,  1000]\n",
      "[4,  1200]\n",
      "[4,  1400]\n",
      "[4,  1600]\n",
      "[4,  1800]\n",
      "[4,  2000]\n",
      "[4,  2200]\n",
      "[4,  2400]\n",
      "[4,  2600]\n",
      "[4,  2800]\n",
      "3 Epoch train Loss: 0.0319 Acc: 0.6353\n",
      "[4,   200]\n",
      "[4,   400]\n",
      "[4,   600]\n",
      "[4,   800]\n",
      "[4,  1000]\n",
      "[4,  1200]\n",
      "[4,  1400]\n",
      "[4,  1600]\n",
      "[4,  1800]\n",
      "[4,  2000]\n",
      "[4,  2200]\n",
      "[4,  2400]\n",
      "[4,  2600]\n",
      "[4,  2800]\n",
      "3 Epoch val Loss: 0.0339 Acc: 0.6111\n",
      "[5,   200]\n",
      "[5,   400]\n",
      "[5,   600]\n",
      "[5,   800]\n",
      "[5,  1000]\n",
      "[5,  1200]\n",
      "[5,  1400]\n",
      "[5,  1600]\n",
      "[5,  1800]\n",
      "[5,  2000]\n",
      "[5,  2200]\n",
      "[5,  2400]\n",
      "[5,  2600]\n",
      "[5,  2800]\n",
      "4 Epoch train Loss: 0.0283 Acc: 0.6775\n",
      "[5,   200]\n",
      "[5,   400]\n",
      "[5,   600]\n",
      "[5,   800]\n",
      "[5,  1000]\n",
      "[5,  1200]\n",
      "[5,  1400]\n",
      "[5,  1600]\n",
      "[5,  1800]\n",
      "[5,  2000]\n",
      "[5,  2200]\n",
      "[5,  2400]\n",
      "[5,  2600]\n",
      "[5,  2800]\n",
      "4 Epoch val Loss: 0.0324 Acc: 0.6377\n",
      "[6,   200]\n",
      "[6,   400]\n",
      "[6,   600]\n",
      "[6,   800]\n",
      "[6,  1000]\n",
      "[6,  1200]\n",
      "[6,  1400]\n",
      "[6,  1600]\n",
      "[6,  1800]\n",
      "[6,  2000]\n",
      "[6,  2200]\n",
      "[6,  2400]\n",
      "[6,  2600]\n",
      "[6,  2800]\n",
      "5 Epoch train Loss: 0.0250 Acc: 0.7176\n",
      "[6,   200]\n",
      "[6,   400]\n",
      "[6,   600]\n",
      "[6,   800]\n",
      "[6,  1000]\n",
      "[6,  1200]\n",
      "[6,  1400]\n",
      "[6,  1600]\n",
      "[6,  1800]\n",
      "[6,  2000]\n",
      "[6,  2200]\n",
      "[6,  2400]\n",
      "[6,  2600]\n",
      "[6,  2800]\n",
      "5 Epoch val Loss: 0.0296 Acc: 0.6673\n",
      "[7,   200]\n",
      "[7,   400]\n",
      "[7,   600]\n",
      "[7,   800]\n",
      "[7,  1000]\n",
      "[7,  1200]\n",
      "[7,  1400]\n",
      "[7,  1600]\n",
      "[7,  1800]\n",
      "[7,  2000]\n",
      "[7,  2200]\n",
      "[7,  2400]\n",
      "[7,  2600]\n",
      "[7,  2800]\n",
      "6 Epoch train Loss: 0.0219 Acc: 0.7526\n",
      "[7,   200]\n",
      "[7,   400]\n",
      "[7,   600]\n",
      "[7,   800]\n",
      "[7,  1000]\n",
      "[7,  1200]\n",
      "[7,  1400]\n",
      "[7,  1600]\n",
      "[7,  1800]\n",
      "[7,  2000]\n",
      "[7,  2200]\n",
      "[7,  2400]\n",
      "[7,  2600]\n",
      "[7,  2800]\n",
      "6 Epoch val Loss: 0.0325 Acc: 0.6459\n",
      "[8,   200]\n",
      "[8,   400]\n",
      "[8,   600]\n",
      "[8,   800]\n",
      "[8,  1000]\n",
      "[8,  1200]\n",
      "[8,  1400]\n",
      "[8,  1600]\n",
      "[8,  1800]\n",
      "[8,  2000]\n",
      "[8,  2200]\n",
      "[8,  2400]\n",
      "[8,  2600]\n",
      "[8,  2800]\n",
      "7 Epoch train Loss: 0.0186 Acc: 0.7892\n",
      "[8,   200]\n",
      "[8,   400]\n",
      "[8,   600]\n",
      "[8,   800]\n",
      "[8,  1000]\n",
      "[8,  1200]\n",
      "[8,  1400]\n",
      "[8,  1600]\n",
      "[8,  1800]\n",
      "[8,  2000]\n",
      "[8,  2200]\n",
      "[8,  2400]\n",
      "[8,  2600]\n",
      "[8,  2800]\n",
      "7 Epoch val Loss: 0.0332 Acc: 0.6513\n",
      "[9,   200]\n",
      "[9,   400]\n",
      "[9,   600]\n",
      "[9,   800]\n",
      "[9,  1000]\n",
      "[9,  1200]\n",
      "[9,  1400]\n",
      "[9,  1600]\n",
      "[9,  1800]\n",
      "[9,  2000]\n",
      "[9,  2200]\n",
      "[9,  2400]\n",
      "[9,  2600]\n",
      "[9,  2800]\n",
      "8 Epoch train Loss: 0.0155 Acc: 0.8262\n",
      "[9,   200]\n",
      "[9,   400]\n",
      "[9,   600]\n",
      "[9,   800]\n",
      "[9,  1000]\n",
      "[9,  1200]\n",
      "[9,  1400]\n",
      "[9,  1600]\n",
      "[9,  1800]\n",
      "[9,  2000]\n",
      "[9,  2200]\n",
      "[9,  2400]\n",
      "[9,  2600]\n",
      "[9,  2800]\n",
      "8 Epoch val Loss: 0.0337 Acc: 0.6610\n",
      "[10,   200]\n",
      "[10,   400]\n",
      "[10,   600]\n",
      "[10,   800]\n",
      "[10,  1000]\n",
      "[10,  1200]\n",
      "[10,  1400]\n",
      "[10,  1600]\n",
      "[10,  1800]\n",
      "[10,  2000]\n",
      "[10,  2200]\n",
      "[10,  2400]\n",
      "[10,  2600]\n",
      "[10,  2800]\n",
      "9 Epoch train Loss: 0.0127 Acc: 0.8585\n",
      "[10,   200]\n",
      "[10,   400]\n",
      "[10,   600]\n",
      "[10,   800]\n",
      "[10,  1000]\n",
      "[10,  1200]\n",
      "[10,  1400]\n",
      "[10,  1600]\n",
      "[10,  1800]\n",
      "[10,  2000]\n",
      "[10,  2200]\n",
      "[10,  2400]\n",
      "[10,  2600]\n",
      "[10,  2800]\n",
      "9 Epoch val Loss: 0.0366 Acc: 0.6451\n",
      "[11,   200]\n",
      "[11,   400]\n",
      "[11,   600]\n",
      "[11,   800]\n",
      "[11,  1000]\n",
      "[11,  1200]\n",
      "[11,  1400]\n",
      "[11,  1600]\n",
      "[11,  1800]\n",
      "[11,  2000]\n",
      "[11,  2200]\n",
      "[11,  2400]\n",
      "[11,  2600]\n",
      "[11,  2800]\n",
      "10 Epoch train Loss: 0.0099 Acc: 0.8915\n",
      "[11,   200]\n",
      "[11,   400]\n",
      "[11,   600]\n",
      "[11,   800]\n",
      "[11,  1000]\n",
      "[11,  1200]\n",
      "[11,  1400]\n",
      "[11,  1600]\n",
      "[11,  1800]\n",
      "[11,  2000]\n",
      "[11,  2200]\n",
      "[11,  2400]\n",
      "[11,  2600]\n",
      "[11,  2800]\n",
      "10 Epoch val Loss: 0.0436 Acc: 0.6091\n",
      "[12,   200]\n",
      "[12,   400]\n",
      "[12,   600]\n",
      "[12,   800]\n",
      "[12,  1000]\n",
      "[12,  1200]\n",
      "[12,  1400]\n",
      "[12,  1600]\n",
      "[12,  1800]\n",
      "[12,  2000]\n",
      "[12,  2200]\n",
      "[12,  2400]\n",
      "[12,  2600]\n",
      "[12,  2800]\n",
      "11 Epoch train Loss: 0.0080 Acc: 0.9115\n",
      "[12,   200]\n",
      "[12,   400]\n",
      "[12,   600]\n",
      "[12,   800]\n",
      "[12,  1000]\n",
      "[12,  1200]\n",
      "[12,  1400]\n",
      "[12,  1600]\n",
      "[12,  1800]\n",
      "[12,  2000]\n",
      "[12,  2200]\n",
      "[12,  2400]\n",
      "[12,  2600]\n",
      "[12,  2800]\n",
      "11 Epoch val Loss: 0.0457 Acc: 0.6178\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-04.\n",
      "[13,   200]\n",
      "[13,   400]\n",
      "[13,   600]\n",
      "[13,   800]\n",
      "[13,  1000]\n",
      "[13,  1200]\n",
      "[13,  1400]\n",
      "[13,  1600]\n",
      "[13,  1800]\n",
      "[13,  2000]\n",
      "[13,  2200]\n",
      "[13,  2400]\n",
      "[13,  2600]\n",
      "[13,  2800]\n",
      "12 Epoch train Loss: 0.0030 Acc: 0.9772\n",
      "[13,   200]\n",
      "[13,   400]\n",
      "[13,   600]\n",
      "[13,   800]\n",
      "[13,  1000]\n",
      "[13,  1200]\n",
      "[13,  1400]\n",
      "[13,  1600]\n",
      "[13,  1800]\n",
      "[13,  2000]\n",
      "[13,  2200]\n",
      "[13,  2400]\n",
      "[13,  2600]\n",
      "[13,  2800]\n",
      "12 Epoch val Loss: 0.0321 Acc: 0.7005\n",
      "[14,   200]\n",
      "[14,   400]\n",
      "[14,   600]\n",
      "[14,   800]\n",
      "[14,  1000]\n",
      "[14,  1200]\n",
      "[14,  1400]\n",
      "[14,  1600]\n",
      "[14,  1800]\n",
      "[14,  2000]\n",
      "[14,  2200]\n",
      "[14,  2400]\n",
      "[14,  2600]\n",
      "[14,  2800]\n",
      "13 Epoch train Loss: 0.0016 Acc: 0.9922\n",
      "[14,   200]\n",
      "[14,   400]\n",
      "[14,   600]\n",
      "[14,   800]\n",
      "[14,  1000]\n",
      "[14,  1200]\n",
      "[14,  1400]\n",
      "[14,  1600]\n",
      "[14,  1800]\n",
      "[14,  2000]\n",
      "[14,  2200]\n",
      "[14,  2400]\n",
      "[14,  2600]\n",
      "[14,  2800]\n",
      "13 Epoch val Loss: 0.0329 Acc: 0.7009\n",
      "[15,   200]\n",
      "[15,   400]\n",
      "[15,   600]\n",
      "[15,   800]\n",
      "[15,  1000]\n",
      "[15,  1200]\n",
      "[15,  1400]\n",
      "[15,  1600]\n",
      "[15,  1800]\n",
      "[15,  2000]\n",
      "[15,  2200]\n",
      "[15,  2400]\n",
      "[15,  2600]\n",
      "[15,  2800]\n",
      "14 Epoch train Loss: 0.0012 Acc: 0.9960\n",
      "[15,   200]\n",
      "[15,   400]\n",
      "[15,   600]\n",
      "[15,   800]\n",
      "[15,  1000]\n",
      "[15,  1200]\n",
      "[15,  1400]\n",
      "[15,  1600]\n",
      "[15,  1800]\n",
      "[15,  2000]\n",
      "[15,  2200]\n",
      "[15,  2400]\n",
      "[15,  2600]\n",
      "[15,  2800]\n",
      "14 Epoch val Loss: 0.0331 Acc: 0.7030\n",
      "[16,   200]\n",
      "[16,   400]\n",
      "[16,   600]\n",
      "[16,   800]\n",
      "[16,  1000]\n",
      "[16,  1200]\n",
      "[16,  1400]\n",
      "[16,  1600]\n",
      "[16,  1800]\n",
      "[16,  2000]\n",
      "[16,  2200]\n",
      "[16,  2400]\n",
      "[16,  2600]\n",
      "[16,  2800]\n",
      "15 Epoch train Loss: 0.0010 Acc: 0.9973\n",
      "[16,   200]\n",
      "[16,   400]\n",
      "[16,   600]\n",
      "[16,   800]\n",
      "[16,  1000]\n",
      "[16,  1200]\n",
      "[16,  1400]\n",
      "[16,  1600]\n",
      "[16,  1800]\n",
      "[16,  2000]\n",
      "[16,  2200]\n",
      "[16,  2400]\n",
      "[16,  2600]\n",
      "[16,  2800]\n",
      "15 Epoch val Loss: 0.0339 Acc: 0.7022\n",
      "[17,   200]\n",
      "[17,   400]\n",
      "[17,   600]\n",
      "[17,   800]\n",
      "[17,  1000]\n",
      "[17,  1200]\n",
      "[17,  1400]\n",
      "[17,  1600]\n",
      "[17,  1800]\n",
      "[17,  2000]\n",
      "[17,  2200]\n",
      "[17,  2400]\n",
      "[17,  2600]\n",
      "[17,  2800]\n",
      "16 Epoch train Loss: 0.0008 Acc: 0.9982\n",
      "[17,   200]\n",
      "[17,   400]\n",
      "[17,   600]\n",
      "[17,   800]\n",
      "[17,  1000]\n",
      "[17,  1200]\n",
      "[17,  1400]\n",
      "[17,  1600]\n",
      "[17,  1800]\n",
      "[17,  2000]\n",
      "[17,  2200]\n",
      "[17,  2400]\n",
      "[17,  2600]\n",
      "[17,  2800]\n",
      "16 Epoch val Loss: 0.0337 Acc: 0.7029\n",
      "[18,   200]\n",
      "[18,   400]\n",
      "[18,   600]\n",
      "[18,   800]\n",
      "[18,  1000]\n",
      "[18,  1200]\n",
      "[18,  1400]\n",
      "[18,  1600]\n",
      "[18,  1800]\n",
      "[18,  2000]\n",
      "[18,  2200]\n",
      "[18,  2400]\n",
      "[18,  2600]\n",
      "[18,  2800]\n",
      "17 Epoch train Loss: 0.0007 Acc: 0.9987\n",
      "[18,   200]\n",
      "[18,   400]\n",
      "[18,   600]\n",
      "[18,   800]\n",
      "[18,  1000]\n",
      "[18,  1200]\n",
      "[18,  1400]\n",
      "[18,  1600]\n",
      "[18,  1800]\n",
      "[18,  2000]\n",
      "[18,  2200]\n",
      "[18,  2400]\n",
      "[18,  2600]\n",
      "[18,  2800]\n",
      "17 Epoch val Loss: 0.0343 Acc: 0.7022\n",
      "[19,   200]\n",
      "[19,   400]\n",
      "[19,   600]\n",
      "[19,   800]\n",
      "[19,  1000]\n",
      "[19,  1200]\n",
      "[19,  1400]\n",
      "[19,  1600]\n",
      "[19,  1800]\n",
      "[19,  2000]\n",
      "[19,  2200]\n",
      "[19,  2400]\n",
      "[19,  2600]\n",
      "[19,  2800]\n",
      "18 Epoch train Loss: 0.0006 Acc: 0.9990\n",
      "[19,   200]\n",
      "[19,   400]\n",
      "[19,   600]\n",
      "[19,   800]\n",
      "[19,  1000]\n",
      "[19,  1200]\n",
      "[19,  1400]\n",
      "[19,  1600]\n",
      "[19,  1800]\n",
      "[19,  2000]\n",
      "[19,  2200]\n",
      "[19,  2400]\n",
      "[19,  2600]\n",
      "[19,  2800]\n",
      "18 Epoch val Loss: 0.0347 Acc: 0.7027\n",
      "[20,   200]\n",
      "[20,   400]\n",
      "[20,   600]\n",
      "[20,   800]\n",
      "[20,  1000]\n",
      "[20,  1200]\n",
      "[20,  1400]\n",
      "[20,  1600]\n",
      "[20,  1800]\n",
      "[20,  2000]\n",
      "[20,  2200]\n",
      "[20,  2400]\n",
      "[20,  2600]\n",
      "[20,  2800]\n",
      "19 Epoch train Loss: 0.0006 Acc: 0.9991\n",
      "[20,   200]\n",
      "[20,   400]\n",
      "[20,   600]\n",
      "[20,   800]\n",
      "[20,  1000]\n",
      "[20,  1200]\n",
      "[20,  1400]\n",
      "[20,  1600]\n",
      "[20,  1800]\n",
      "[20,  2000]\n",
      "[20,  2200]\n",
      "[20,  2400]\n",
      "[20,  2600]\n",
      "[20,  2800]\n",
      "19 Epoch val Loss: 0.0350 Acc: 0.7039\n",
      "[21,   200]\n",
      "[21,   400]\n",
      "[21,   600]\n",
      "[21,   800]\n",
      "[21,  1000]\n",
      "[21,  1200]\n",
      "[21,  1400]\n",
      "[21,  1600]\n",
      "[21,  1800]\n",
      "[21,  2000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21,  2200]\n",
      "[21,  2400]\n",
      "[21,  2600]\n",
      "[21,  2800]\n",
      "20 Epoch train Loss: 0.0005 Acc: 0.9992\n",
      "[21,   200]\n",
      "[21,   400]\n",
      "[21,   600]\n",
      "[21,   800]\n",
      "[21,  1000]\n",
      "[21,  1200]\n",
      "[21,  1400]\n",
      "[21,  1600]\n",
      "[21,  1800]\n",
      "[21,  2000]\n",
      "[21,  2200]\n",
      "[21,  2400]\n",
      "[21,  2600]\n",
      "[21,  2800]\n",
      "20 Epoch val Loss: 0.0349 Acc: 0.7035\n",
      "[22,   200]\n",
      "[22,   400]\n",
      "[22,   600]\n",
      "[22,   800]\n",
      "[22,  1000]\n",
      "[22,  1200]\n",
      "[22,  1400]\n",
      "[22,  1600]\n",
      "[22,  1800]\n",
      "[22,  2000]\n",
      "[22,  2200]\n",
      "[22,  2400]\n",
      "[22,  2600]\n",
      "[22,  2800]\n",
      "21 Epoch train Loss: 0.0005 Acc: 0.9995\n",
      "[22,   200]\n",
      "[22,   400]\n",
      "[22,   600]\n",
      "[22,   800]\n",
      "[22,  1000]\n",
      "[22,  1200]\n",
      "[22,  1400]\n",
      "[22,  1600]\n",
      "[22,  1800]\n",
      "[22,  2000]\n",
      "[22,  2200]\n",
      "[22,  2400]\n",
      "[22,  2600]\n",
      "[22,  2800]\n",
      "21 Epoch val Loss: 0.0353 Acc: 0.7017\n",
      "[23,   200]\n",
      "[23,   400]\n",
      "[23,   600]\n",
      "[23,   800]\n",
      "[23,  1000]\n",
      "[23,  1200]\n",
      "[23,  1400]\n",
      "[23,  1600]\n",
      "[23,  1800]\n",
      "[23,  2000]\n",
      "[23,  2200]\n",
      "[23,  2400]\n",
      "[23,  2600]\n",
      "[23,  2800]\n",
      "22 Epoch train Loss: 0.0004 Acc: 0.9994\n",
      "[23,   200]\n",
      "[23,   400]\n",
      "[23,   600]\n",
      "[23,   800]\n",
      "[23,  1000]\n",
      "[23,  1200]\n",
      "[23,  1400]\n",
      "[23,  1600]\n",
      "[23,  1800]\n",
      "[23,  2000]\n",
      "[23,  2200]\n",
      "[23,  2400]\n",
      "[23,  2600]\n",
      "[23,  2800]\n",
      "22 Epoch val Loss: 0.0354 Acc: 0.7024\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-05.\n",
      "[24,   200]\n",
      "[24,   400]\n",
      "[24,   600]\n",
      "[24,   800]\n",
      "[24,  1000]\n",
      "[24,  1200]\n",
      "[24,  1400]\n",
      "[24,  1600]\n",
      "[24,  1800]\n",
      "[24,  2000]\n",
      "[24,  2200]\n",
      "[24,  2400]\n",
      "[24,  2600]\n",
      "[24,  2800]\n",
      "23 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[24,   200]\n",
      "[24,   400]\n",
      "[24,   600]\n",
      "[24,   800]\n",
      "[24,  1000]\n",
      "[24,  1200]\n",
      "[24,  1400]\n",
      "[24,  1600]\n",
      "[24,  1800]\n",
      "[24,  2000]\n",
      "[24,  2200]\n",
      "[24,  2400]\n",
      "[24,  2600]\n",
      "[24,  2800]\n",
      "23 Epoch val Loss: 0.0355 Acc: 0.7033\n",
      "[25,   200]\n",
      "[25,   400]\n",
      "[25,   600]\n",
      "[25,   800]\n",
      "[25,  1000]\n",
      "[25,  1200]\n",
      "[25,  1400]\n",
      "[25,  1600]\n",
      "[25,  1800]\n",
      "[25,  2000]\n",
      "[25,  2200]\n",
      "[25,  2400]\n",
      "[25,  2600]\n",
      "[25,  2800]\n",
      "24 Epoch train Loss: 0.0004 Acc: 0.9994\n",
      "[25,   200]\n",
      "[25,   400]\n",
      "[25,   600]\n",
      "[25,   800]\n",
      "[25,  1000]\n",
      "[25,  1200]\n",
      "[25,  1400]\n",
      "[25,  1600]\n",
      "[25,  1800]\n",
      "[25,  2000]\n",
      "[25,  2200]\n",
      "[25,  2400]\n",
      "[25,  2600]\n",
      "[25,  2800]\n",
      "24 Epoch val Loss: 0.0353 Acc: 0.7027\n",
      "[26,   200]\n",
      "[26,   400]\n",
      "[26,   600]\n",
      "[26,   800]\n",
      "[26,  1000]\n",
      "[26,  1200]\n",
      "[26,  1400]\n",
      "[26,  1600]\n",
      "[26,  1800]\n",
      "[26,  2000]\n",
      "[26,  2200]\n",
      "[26,  2400]\n",
      "[26,  2600]\n",
      "[26,  2800]\n",
      "25 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[26,   200]\n",
      "[26,   400]\n",
      "[26,   600]\n",
      "[26,   800]\n",
      "[26,  1000]\n",
      "[26,  1200]\n",
      "[26,  1400]\n",
      "[26,  1600]\n",
      "[26,  1800]\n",
      "[26,  2000]\n",
      "[26,  2200]\n",
      "[26,  2400]\n",
      "[26,  2600]\n",
      "[26,  2800]\n",
      "25 Epoch val Loss: 0.0352 Acc: 0.7036\n",
      "[27,   200]\n",
      "[27,   400]\n",
      "[27,   600]\n",
      "[27,   800]\n",
      "[27,  1000]\n",
      "[27,  1200]\n",
      "[27,  1400]\n",
      "[27,  1600]\n",
      "[27,  1800]\n",
      "[27,  2000]\n",
      "[27,  2200]\n",
      "[27,  2400]\n",
      "[27,  2600]\n",
      "[27,  2800]\n",
      "26 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[27,   200]\n",
      "[27,   400]\n",
      "[27,   600]\n",
      "[27,   800]\n",
      "[27,  1000]\n",
      "[27,  1200]\n",
      "[27,  1400]\n",
      "[27,  1600]\n",
      "[27,  1800]\n",
      "[27,  2000]\n",
      "[27,  2200]\n",
      "[27,  2400]\n",
      "[27,  2600]\n",
      "[27,  2800]\n",
      "26 Epoch val Loss: 0.0353 Acc: 0.7025\n",
      "[28,   200]\n",
      "[28,   400]\n",
      "[28,   600]\n",
      "[28,   800]\n",
      "[28,  1000]\n",
      "[28,  1200]\n",
      "[28,  1400]\n",
      "[28,  1600]\n",
      "[28,  1800]\n",
      "[28,  2000]\n",
      "[28,  2200]\n",
      "[28,  2400]\n",
      "[28,  2600]\n",
      "[28,  2800]\n",
      "27 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[28,   200]\n",
      "[28,   400]\n",
      "[28,   600]\n",
      "[28,   800]\n",
      "[28,  1000]\n",
      "[28,  1200]\n",
      "[28,  1400]\n",
      "[28,  1600]\n",
      "[28,  1800]\n",
      "[28,  2000]\n",
      "[28,  2200]\n",
      "[28,  2400]\n",
      "[28,  2600]\n",
      "[28,  2800]\n",
      "27 Epoch val Loss: 0.0354 Acc: 0.7028\n",
      "[29,   200]\n",
      "[29,   400]\n",
      "[29,   600]\n",
      "[29,   800]\n",
      "[29,  1000]\n",
      "[29,  1200]\n",
      "[29,  1400]\n",
      "[29,  1600]\n",
      "[29,  1800]\n",
      "[29,  2000]\n",
      "[29,  2200]\n",
      "[29,  2400]\n",
      "[29,  2600]\n",
      "[29,  2800]\n",
      "28 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[29,   200]\n",
      "[29,   400]\n",
      "[29,   600]\n",
      "[29,   800]\n",
      "[29,  1000]\n",
      "[29,  1200]\n",
      "[29,  1400]\n",
      "[29,  1600]\n",
      "[29,  1800]\n",
      "[29,  2000]\n",
      "[29,  2200]\n",
      "[29,  2400]\n",
      "[29,  2600]\n",
      "[29,  2800]\n",
      "28 Epoch val Loss: 0.0356 Acc: 0.7021\n",
      "[30,   200]\n",
      "[30,   400]\n",
      "[30,   600]\n",
      "[30,   800]\n",
      "[30,  1000]\n",
      "[30,  1200]\n",
      "[30,  1400]\n",
      "[30,  1600]\n",
      "[30,  1800]\n",
      "[30,  2000]\n",
      "[30,  2200]\n",
      "[30,  2400]\n",
      "[30,  2600]\n",
      "[30,  2800]\n",
      "29 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[30,   200]\n",
      "[30,   400]\n",
      "[30,   600]\n",
      "[30,   800]\n",
      "[30,  1000]\n",
      "[30,  1200]\n",
      "[30,  1400]\n",
      "[30,  1600]\n",
      "[30,  1800]\n",
      "[30,  2000]\n",
      "[30,  2200]\n",
      "[30,  2400]\n",
      "[30,  2600]\n",
      "[30,  2800]\n",
      "29 Epoch val Loss: 0.0354 Acc: 0.7025\n",
      "[31,   200]\n",
      "[31,   400]\n",
      "[31,   600]\n",
      "[31,   800]\n",
      "[31,  1000]\n",
      "[31,  1200]\n",
      "[31,  1400]\n",
      "[31,  1600]\n",
      "[31,  1800]\n",
      "[31,  2000]\n",
      "[31,  2200]\n",
      "[31,  2400]\n",
      "[31,  2600]\n",
      "[31,  2800]\n",
      "30 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[31,   200]\n",
      "[31,   400]\n",
      "[31,   600]\n",
      "[31,   800]\n",
      "[31,  1000]\n",
      "[31,  1200]\n",
      "[31,  1400]\n",
      "[31,  1600]\n",
      "[31,  1800]\n",
      "[31,  2000]\n",
      "[31,  2200]\n",
      "[31,  2400]\n",
      "[31,  2600]\n",
      "[31,  2800]\n",
      "30 Epoch val Loss: 0.0356 Acc: 0.7033\n",
      "[32,   200]\n",
      "[32,   400]\n",
      "[32,   600]\n",
      "[32,   800]\n",
      "[32,  1000]\n",
      "[32,  1200]\n",
      "[32,  1400]\n",
      "[32,  1600]\n",
      "[32,  1800]\n",
      "[32,  2000]\n",
      "[32,  2200]\n",
      "[32,  2400]\n",
      "[32,  2600]\n",
      "[32,  2800]\n",
      "31 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[32,   200]\n",
      "[32,   400]\n",
      "[32,   600]\n",
      "[32,   800]\n",
      "[32,  1000]\n",
      "[32,  1200]\n",
      "[32,  1400]\n",
      "[32,  1600]\n",
      "[32,  1800]\n",
      "[32,  2000]\n",
      "[32,  2200]\n",
      "[32,  2400]\n",
      "[32,  2600]\n",
      "[32,  2800]\n",
      "31 Epoch val Loss: 0.0355 Acc: 0.7032\n",
      "[33,   200]\n",
      "[33,   400]\n",
      "[33,   600]\n",
      "[33,   800]\n",
      "[33,  1000]\n",
      "[33,  1200]\n",
      "[33,  1400]\n",
      "[33,  1600]\n",
      "[33,  1800]\n",
      "[33,  2000]\n",
      "[33,  2200]\n",
      "[33,  2400]\n",
      "[33,  2600]\n",
      "[33,  2800]\n",
      "32 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[33,   200]\n",
      "[33,   400]\n",
      "[33,   600]\n",
      "[33,   800]\n",
      "[33,  1000]\n",
      "[33,  1200]\n",
      "[33,  1400]\n",
      "[33,  1600]\n",
      "[33,  1800]\n",
      "[33,  2000]\n",
      "[33,  2200]\n",
      "[33,  2400]\n",
      "[33,  2600]\n",
      "[33,  2800]\n",
      "32 Epoch val Loss: 0.0355 Acc: 0.7033\n",
      "[34,   200]\n",
      "[34,   400]\n",
      "[34,   600]\n",
      "[34,   800]\n",
      "[34,  1000]\n",
      "[34,  1200]\n",
      "[34,  1400]\n",
      "[34,  1600]\n",
      "[34,  1800]\n",
      "[34,  2000]\n",
      "[34,  2200]\n",
      "[34,  2400]\n",
      "[34,  2600]\n",
      "[34,  2800]\n",
      "33 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[34,   200]\n",
      "[34,   400]\n",
      "[34,   600]\n",
      "[34,   800]\n",
      "[34,  1000]\n",
      "[34,  1200]\n",
      "[34,  1400]\n",
      "[34,  1600]\n",
      "[34,  1800]\n",
      "[34,  2000]\n",
      "[34,  2200]\n",
      "[34,  2400]\n",
      "[34,  2600]\n",
      "[34,  2800]\n",
      "33 Epoch val Loss: 0.0356 Acc: 0.7029\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-06.\n",
      "[35,   200]\n",
      "[35,   400]\n",
      "[35,   600]\n",
      "[35,   800]\n",
      "[35,  1000]\n",
      "[35,  1200]\n",
      "[35,  1400]\n",
      "[35,  1600]\n",
      "[35,  1800]\n",
      "[35,  2000]\n",
      "[35,  2200]\n",
      "[35,  2400]\n",
      "[35,  2600]\n",
      "[35,  2800]\n",
      "34 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[35,   200]\n",
      "[35,   400]\n",
      "[35,   600]\n",
      "[35,   800]\n",
      "[35,  1000]\n",
      "[35,  1200]\n",
      "[35,  1400]\n",
      "[35,  1600]\n",
      "[35,  1800]\n",
      "[35,  2000]\n",
      "[35,  2200]\n",
      "[35,  2400]\n",
      "[35,  2600]\n",
      "[35,  2800]\n",
      "34 Epoch val Loss: 0.0354 Acc: 0.7039\n",
      "[36,   200]\n",
      "[36,   400]\n",
      "[36,   600]\n",
      "[36,   800]\n",
      "[36,  1000]\n",
      "[36,  1200]\n",
      "[36,  1400]\n",
      "[36,  1600]\n",
      "[36,  1800]\n",
      "[36,  2000]\n",
      "[36,  2200]\n",
      "[36,  2400]\n",
      "[36,  2600]\n",
      "[36,  2800]\n",
      "35 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[36,   200]\n",
      "[36,   400]\n",
      "[36,   600]\n",
      "[36,   800]\n",
      "[36,  1000]\n",
      "[36,  1200]\n",
      "[36,  1400]\n",
      "[36,  1600]\n",
      "[36,  1800]\n",
      "[36,  2000]\n",
      "[36,  2200]\n",
      "[36,  2400]\n",
      "[36,  2600]\n",
      "[36,  2800]\n",
      "35 Epoch val Loss: 0.0355 Acc: 0.7038\n",
      "[37,   200]\n",
      "[37,   400]\n",
      "[37,   600]\n",
      "[37,   800]\n",
      "[37,  1000]\n",
      "[37,  1200]\n",
      "[37,  1400]\n",
      "[37,  1600]\n",
      "[37,  1800]\n",
      "[37,  2000]\n",
      "[37,  2200]\n",
      "[37,  2400]\n",
      "[37,  2600]\n",
      "[37,  2800]\n",
      "36 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[37,   200]\n",
      "[37,   400]\n",
      "[37,   600]\n",
      "[37,   800]\n",
      "[37,  1000]\n",
      "[37,  1200]\n",
      "[37,  1400]\n",
      "[37,  1600]\n",
      "[37,  1800]\n",
      "[37,  2000]\n",
      "[37,  2200]\n",
      "[37,  2400]\n",
      "[37,  2600]\n",
      "[37,  2800]\n",
      "36 Epoch val Loss: 0.0357 Acc: 0.7018\n",
      "[38,   200]\n",
      "[38,   400]\n",
      "[38,   600]\n",
      "[38,   800]\n",
      "[38,  1000]\n",
      "[38,  1200]\n",
      "[38,  1400]\n",
      "[38,  1600]\n",
      "[38,  1800]\n",
      "[38,  2000]\n",
      "[38,  2200]\n",
      "[38,  2400]\n",
      "[38,  2600]\n",
      "[38,  2800]\n",
      "37 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[38,   200]\n",
      "[38,   400]\n",
      "[38,   600]\n",
      "[38,   800]\n",
      "[38,  1000]\n",
      "[38,  1200]\n",
      "[38,  1400]\n",
      "[38,  1600]\n",
      "[38,  1800]\n",
      "[38,  2000]\n",
      "[38,  2200]\n",
      "[38,  2400]\n",
      "[38,  2600]\n",
      "[38,  2800]\n",
      "37 Epoch val Loss: 0.0357 Acc: 0.7026\n",
      "[39,   200]\n",
      "[39,   400]\n",
      "[39,   600]\n",
      "[39,   800]\n",
      "[39,  1000]\n",
      "[39,  1200]\n",
      "[39,  1400]\n",
      "[39,  1600]\n",
      "[39,  1800]\n",
      "[39,  2000]\n",
      "[39,  2200]\n",
      "[39,  2400]\n",
      "[39,  2600]\n",
      "[39,  2800]\n",
      "38 Epoch train Loss: 0.0004 Acc: 0.9997\n",
      "[39,   200]\n",
      "[39,   400]\n",
      "[39,   600]\n",
      "[39,   800]\n",
      "[39,  1000]\n",
      "[39,  1200]\n",
      "[39,  1400]\n",
      "[39,  1600]\n",
      "[39,  1800]\n",
      "[39,  2000]\n",
      "[39,  2200]\n",
      "[39,  2400]\n",
      "[39,  2600]\n",
      "[39,  2800]\n",
      "38 Epoch val Loss: 0.0354 Acc: 0.7038\n",
      "[40,   200]\n",
      "[40,   400]\n",
      "[40,   600]\n",
      "[40,   800]\n",
      "[40,  1000]\n",
      "[40,  1200]\n",
      "[40,  1400]\n",
      "[40,  1600]\n",
      "[40,  1800]\n",
      "[40,  2000]\n",
      "[40,  2200]\n",
      "[40,  2400]\n",
      "[40,  2600]\n",
      "[40,  2800]\n",
      "39 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[40,   200]\n",
      "[40,   400]\n",
      "[40,   600]\n",
      "[40,   800]\n",
      "[40,  1000]\n",
      "[40,  1200]\n",
      "[40,  1400]\n",
      "[40,  1600]\n",
      "[40,  1800]\n",
      "[40,  2000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40,  2200]\n",
      "[40,  2400]\n",
      "[40,  2600]\n",
      "[40,  2800]\n",
      "39 Epoch val Loss: 0.0356 Acc: 0.7019\n",
      "[41,   200]\n",
      "[41,   400]\n",
      "[41,   600]\n",
      "[41,   800]\n",
      "[41,  1000]\n",
      "[41,  1200]\n",
      "[41,  1400]\n",
      "[41,  1600]\n",
      "[41,  1800]\n",
      "[41,  2000]\n",
      "[41,  2200]\n",
      "[41,  2400]\n",
      "[41,  2600]\n",
      "[41,  2800]\n",
      "40 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[41,   200]\n",
      "[41,   400]\n",
      "[41,   600]\n",
      "[41,   800]\n",
      "[41,  1000]\n",
      "[41,  1200]\n",
      "[41,  1400]\n",
      "[41,  1600]\n",
      "[41,  1800]\n",
      "[41,  2000]\n",
      "[41,  2200]\n",
      "[41,  2400]\n",
      "[41,  2600]\n",
      "[41,  2800]\n",
      "40 Epoch val Loss: 0.0357 Acc: 0.7023\n",
      "[42,   200]\n",
      "[42,   400]\n",
      "[42,   600]\n",
      "[42,   800]\n",
      "[42,  1000]\n",
      "[42,  1200]\n",
      "[42,  1400]\n",
      "[42,  1600]\n",
      "[42,  1800]\n",
      "[42,  2000]\n",
      "[42,  2200]\n",
      "[42,  2400]\n",
      "[42,  2600]\n",
      "[42,  2800]\n",
      "41 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[42,   200]\n",
      "[42,   400]\n",
      "[42,   600]\n",
      "[42,   800]\n",
      "[42,  1000]\n",
      "[42,  1200]\n",
      "[42,  1400]\n",
      "[42,  1600]\n",
      "[42,  1800]\n",
      "[42,  2000]\n",
      "[42,  2200]\n",
      "[42,  2400]\n",
      "[42,  2600]\n",
      "[42,  2800]\n",
      "41 Epoch val Loss: 0.0355 Acc: 0.7032\n",
      "[43,   200]\n",
      "[43,   400]\n",
      "[43,   600]\n",
      "[43,   800]\n",
      "[43,  1000]\n",
      "[43,  1200]\n",
      "[43,  1400]\n",
      "[43,  1600]\n",
      "[43,  1800]\n",
      "[43,  2000]\n",
      "[43,  2200]\n",
      "[43,  2400]\n",
      "[43,  2600]\n",
      "[43,  2800]\n",
      "42 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[43,   200]\n",
      "[43,   400]\n",
      "[43,   600]\n",
      "[43,   800]\n",
      "[43,  1000]\n",
      "[43,  1200]\n",
      "[43,  1400]\n",
      "[43,  1600]\n",
      "[43,  1800]\n",
      "[43,  2000]\n",
      "[43,  2200]\n",
      "[43,  2400]\n",
      "[43,  2600]\n",
      "[43,  2800]\n",
      "42 Epoch val Loss: 0.0353 Acc: 0.7037\n",
      "[44,   200]\n",
      "[44,   400]\n",
      "[44,   600]\n",
      "[44,   800]\n",
      "[44,  1000]\n",
      "[44,  1200]\n",
      "[44,  1400]\n",
      "[44,  1600]\n",
      "[44,  1800]\n",
      "[44,  2000]\n",
      "[44,  2200]\n",
      "[44,  2400]\n",
      "[44,  2600]\n",
      "[44,  2800]\n",
      "43 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[44,   200]\n",
      "[44,   400]\n",
      "[44,   600]\n",
      "[44,   800]\n",
      "[44,  1000]\n",
      "[44,  1200]\n",
      "[44,  1400]\n",
      "[44,  1600]\n",
      "[44,  1800]\n",
      "[44,  2000]\n",
      "[44,  2200]\n",
      "[44,  2400]\n",
      "[44,  2600]\n",
      "[44,  2800]\n",
      "43 Epoch val Loss: 0.0354 Acc: 0.7023\n",
      "[45,   200]\n",
      "[45,   400]\n",
      "[45,   600]\n",
      "[45,   800]\n",
      "[45,  1000]\n",
      "[45,  1200]\n",
      "[45,  1400]\n",
      "[45,  1600]\n",
      "[45,  1800]\n",
      "[45,  2000]\n",
      "[45,  2200]\n",
      "[45,  2400]\n",
      "[45,  2600]\n",
      "[45,  2800]\n",
      "44 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[45,   200]\n",
      "[45,   400]\n",
      "[45,   600]\n",
      "[45,   800]\n",
      "[45,  1000]\n",
      "[45,  1200]\n",
      "[45,  1400]\n",
      "[45,  1600]\n",
      "[45,  1800]\n",
      "[45,  2000]\n",
      "[45,  2200]\n",
      "[45,  2400]\n",
      "[45,  2600]\n",
      "[45,  2800]\n",
      "44 Epoch val Loss: 0.0353 Acc: 0.7028\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-07.\n",
      "[46,   200]\n",
      "[46,   400]\n",
      "[46,   600]\n",
      "[46,   800]\n",
      "[46,  1000]\n",
      "[46,  1200]\n",
      "[46,  1400]\n",
      "[46,  1600]\n",
      "[46,  1800]\n",
      "[46,  2000]\n",
      "[46,  2200]\n",
      "[46,  2400]\n",
      "[46,  2600]\n",
      "[46,  2800]\n",
      "45 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[46,   200]\n",
      "[46,   400]\n",
      "[46,   600]\n",
      "[46,   800]\n",
      "[46,  1000]\n",
      "[46,  1200]\n",
      "[46,  1400]\n",
      "[46,  1600]\n",
      "[46,  1800]\n",
      "[46,  2000]\n",
      "[46,  2200]\n",
      "[46,  2400]\n",
      "[46,  2600]\n",
      "[46,  2800]\n",
      "45 Epoch val Loss: 0.0354 Acc: 0.7024\n",
      "[47,   200]\n",
      "[47,   400]\n",
      "[47,   600]\n",
      "[47,   800]\n",
      "[47,  1000]\n",
      "[47,  1200]\n",
      "[47,  1400]\n",
      "[47,  1600]\n",
      "[47,  1800]\n",
      "[47,  2000]\n",
      "[47,  2200]\n",
      "[47,  2400]\n",
      "[47,  2600]\n",
      "[47,  2800]\n",
      "46 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[47,   200]\n",
      "[47,   400]\n",
      "[47,   600]\n",
      "[47,   800]\n",
      "[47,  1000]\n",
      "[47,  1200]\n",
      "[47,  1400]\n",
      "[47,  1600]\n",
      "[47,  1800]\n",
      "[47,  2000]\n",
      "[47,  2200]\n",
      "[47,  2400]\n",
      "[47,  2600]\n",
      "[47,  2800]\n",
      "46 Epoch val Loss: 0.0356 Acc: 0.7028\n",
      "[48,   200]\n",
      "[48,   400]\n",
      "[48,   600]\n",
      "[48,   800]\n",
      "[48,  1000]\n",
      "[48,  1200]\n",
      "[48,  1400]\n",
      "[48,  1600]\n",
      "[48,  1800]\n",
      "[48,  2000]\n",
      "[48,  2200]\n",
      "[48,  2400]\n",
      "[48,  2600]\n",
      "[48,  2800]\n",
      "47 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[48,   200]\n",
      "[48,   400]\n",
      "[48,   600]\n",
      "[48,   800]\n",
      "[48,  1000]\n",
      "[48,  1200]\n",
      "[48,  1400]\n",
      "[48,  1600]\n",
      "[48,  1800]\n",
      "[48,  2000]\n",
      "[48,  2200]\n",
      "[48,  2400]\n",
      "[48,  2600]\n",
      "[48,  2800]\n",
      "47 Epoch val Loss: 0.0355 Acc: 0.7041\n",
      "[49,   200]\n",
      "[49,   400]\n",
      "[49,   600]\n",
      "[49,   800]\n",
      "[49,  1000]\n",
      "[49,  1200]\n",
      "[49,  1400]\n",
      "[49,  1600]\n",
      "[49,  1800]\n",
      "[49,  2000]\n",
      "[49,  2200]\n",
      "[49,  2400]\n",
      "[49,  2600]\n",
      "[49,  2800]\n",
      "48 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[49,   200]\n",
      "[49,   400]\n",
      "[49,   600]\n",
      "[49,   800]\n",
      "[49,  1000]\n",
      "[49,  1200]\n",
      "[49,  1400]\n",
      "[49,  1600]\n",
      "[49,  1800]\n",
      "[49,  2000]\n",
      "[49,  2200]\n",
      "[49,  2400]\n",
      "[49,  2600]\n",
      "[49,  2800]\n",
      "48 Epoch val Loss: 0.0355 Acc: 0.7034\n",
      "[50,   200]\n",
      "[50,   400]\n",
      "[50,   600]\n",
      "[50,   800]\n",
      "[50,  1000]\n",
      "[50,  1200]\n",
      "[50,  1400]\n",
      "[50,  1600]\n",
      "[50,  1800]\n",
      "[50,  2000]\n",
      "[50,  2200]\n",
      "[50,  2400]\n",
      "[50,  2600]\n",
      "[50,  2800]\n",
      "49 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[50,   200]\n",
      "[50,   400]\n",
      "[50,   600]\n",
      "[50,   800]\n",
      "[50,  1000]\n",
      "[50,  1200]\n",
      "[50,  1400]\n",
      "[50,  1600]\n",
      "[50,  1800]\n",
      "[50,  2000]\n",
      "[50,  2200]\n",
      "[50,  2400]\n",
      "[50,  2600]\n",
      "[50,  2800]\n",
      "49 Epoch val Loss: 0.0355 Acc: 0.7038\n",
      "[51,   200]\n",
      "[51,   400]\n",
      "[51,   600]\n",
      "[51,   800]\n",
      "[51,  1000]\n",
      "[51,  1200]\n",
      "[51,  1400]\n",
      "[51,  1600]\n",
      "[51,  1800]\n",
      "[51,  2000]\n",
      "[51,  2200]\n",
      "[51,  2400]\n",
      "[51,  2600]\n",
      "[51,  2800]\n",
      "50 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[51,   200]\n",
      "[51,   400]\n",
      "[51,   600]\n",
      "[51,   800]\n",
      "[51,  1000]\n",
      "[51,  1200]\n",
      "[51,  1400]\n",
      "[51,  1600]\n",
      "[51,  1800]\n",
      "[51,  2000]\n",
      "[51,  2200]\n",
      "[51,  2400]\n",
      "[51,  2600]\n",
      "[51,  2800]\n",
      "50 Epoch val Loss: 0.0357 Acc: 0.7029\n",
      "[52,   200]\n",
      "[52,   400]\n",
      "[52,   600]\n",
      "[52,   800]\n",
      "[52,  1000]\n",
      "[52,  1200]\n",
      "[52,  1400]\n",
      "[52,  1600]\n",
      "[52,  1800]\n",
      "[52,  2000]\n",
      "[52,  2200]\n",
      "[52,  2400]\n",
      "[52,  2600]\n",
      "[52,  2800]\n",
      "51 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[52,   200]\n",
      "[52,   400]\n",
      "[52,   600]\n",
      "[52,   800]\n",
      "[52,  1000]\n",
      "[52,  1200]\n",
      "[52,  1400]\n",
      "[52,  1600]\n",
      "[52,  1800]\n",
      "[52,  2000]\n",
      "[52,  2200]\n",
      "[52,  2400]\n",
      "[52,  2600]\n",
      "[52,  2800]\n",
      "51 Epoch val Loss: 0.0355 Acc: 0.7036\n",
      "[53,   200]\n",
      "[53,   400]\n",
      "[53,   600]\n",
      "[53,   800]\n",
      "[53,  1000]\n",
      "[53,  1200]\n",
      "[53,  1400]\n",
      "[53,  1600]\n",
      "[53,  1800]\n",
      "[53,  2000]\n",
      "[53,  2200]\n",
      "[53,  2400]\n",
      "[53,  2600]\n",
      "[53,  2800]\n",
      "52 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[53,   200]\n",
      "[53,   400]\n",
      "[53,   600]\n",
      "[53,   800]\n",
      "[53,  1000]\n",
      "[53,  1200]\n",
      "[53,  1400]\n",
      "[53,  1600]\n",
      "[53,  1800]\n",
      "[53,  2000]\n",
      "[53,  2200]\n",
      "[53,  2400]\n",
      "[53,  2600]\n",
      "[53,  2800]\n",
      "52 Epoch val Loss: 0.0356 Acc: 0.7036\n",
      "[54,   200]\n",
      "[54,   400]\n",
      "[54,   600]\n",
      "[54,   800]\n",
      "[54,  1000]\n",
      "[54,  1200]\n",
      "[54,  1400]\n",
      "[54,  1600]\n",
      "[54,  1800]\n",
      "[54,  2000]\n",
      "[54,  2200]\n",
      "[54,  2400]\n",
      "[54,  2600]\n",
      "[54,  2800]\n",
      "53 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[54,   200]\n",
      "[54,   400]\n",
      "[54,   600]\n",
      "[54,   800]\n",
      "[54,  1000]\n",
      "[54,  1200]\n",
      "[54,  1400]\n",
      "[54,  1600]\n",
      "[54,  1800]\n",
      "[54,  2000]\n",
      "[54,  2200]\n",
      "[54,  2400]\n",
      "[54,  2600]\n",
      "[54,  2800]\n",
      "53 Epoch val Loss: 0.0355 Acc: 0.7037\n",
      "[55,   200]\n",
      "[55,   400]\n",
      "[55,   600]\n",
      "[55,   800]\n",
      "[55,  1000]\n",
      "[55,  1200]\n",
      "[55,  1400]\n",
      "[55,  1600]\n",
      "[55,  1800]\n",
      "[55,  2000]\n",
      "[55,  2200]\n",
      "[55,  2400]\n",
      "[55,  2600]\n",
      "[55,  2800]\n",
      "54 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[55,   200]\n",
      "[55,   400]\n",
      "[55,   600]\n",
      "[55,   800]\n",
      "[55,  1000]\n",
      "[55,  1200]\n",
      "[55,  1400]\n",
      "[55,  1600]\n",
      "[55,  1800]\n",
      "[55,  2000]\n",
      "[55,  2200]\n",
      "[55,  2400]\n",
      "[55,  2600]\n",
      "[55,  2800]\n",
      "54 Epoch val Loss: 0.0359 Acc: 0.7011\n",
      "[56,   200]\n",
      "[56,   400]\n",
      "[56,   600]\n",
      "[56,   800]\n",
      "[56,  1000]\n",
      "[56,  1200]\n",
      "[56,  1400]\n",
      "[56,  1600]\n",
      "[56,  1800]\n",
      "[56,  2000]\n",
      "[56,  2200]\n",
      "[56,  2400]\n",
      "[56,  2600]\n",
      "[56,  2800]\n",
      "55 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[56,   200]\n",
      "[56,   400]\n",
      "[56,   600]\n",
      "[56,   800]\n",
      "[56,  1000]\n",
      "[56,  1200]\n",
      "[56,  1400]\n",
      "[56,  1600]\n",
      "[56,  1800]\n",
      "[56,  2000]\n",
      "[56,  2200]\n",
      "[56,  2400]\n",
      "[56,  2600]\n",
      "[56,  2800]\n",
      "55 Epoch val Loss: 0.0354 Acc: 0.7041\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-08.\n",
      "[57,   200]\n",
      "[57,   400]\n",
      "[57,   600]\n",
      "[57,   800]\n",
      "[57,  1000]\n",
      "[57,  1200]\n",
      "[57,  1400]\n",
      "[57,  1600]\n",
      "[57,  1800]\n",
      "[57,  2000]\n",
      "[57,  2200]\n",
      "[57,  2400]\n",
      "[57,  2600]\n",
      "[57,  2800]\n",
      "56 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[57,   200]\n",
      "[57,   400]\n",
      "[57,   600]\n",
      "[57,   800]\n",
      "[57,  1000]\n",
      "[57,  1200]\n",
      "[57,  1400]\n",
      "[57,  1600]\n",
      "[57,  1800]\n",
      "[57,  2000]\n",
      "[57,  2200]\n",
      "[57,  2400]\n",
      "[57,  2600]\n",
      "[57,  2800]\n",
      "56 Epoch val Loss: 0.0355 Acc: 0.7032\n",
      "[58,   200]\n",
      "[58,   400]\n",
      "[58,   600]\n",
      "[58,   800]\n",
      "[58,  1000]\n",
      "[58,  1200]\n",
      "[58,  1400]\n",
      "[58,  1600]\n",
      "[58,  1800]\n",
      "[58,  2000]\n",
      "[58,  2200]\n",
      "[58,  2400]\n",
      "[58,  2600]\n",
      "[58,  2800]\n",
      "57 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[58,   200]\n",
      "[58,   400]\n",
      "[58,   600]\n",
      "[58,   800]\n",
      "[58,  1000]\n",
      "[58,  1200]\n",
      "[58,  1400]\n",
      "[58,  1600]\n",
      "[58,  1800]\n",
      "[58,  2000]\n",
      "[58,  2200]\n",
      "[58,  2400]\n",
      "[58,  2600]\n",
      "[58,  2800]\n",
      "57 Epoch val Loss: 0.0356 Acc: 0.7030\n",
      "[59,   200]\n",
      "[59,   400]\n",
      "[59,   600]\n",
      "[59,   800]\n",
      "[59,  1000]\n",
      "[59,  1200]\n",
      "[59,  1400]\n",
      "[59,  1600]\n",
      "[59,  1800]\n",
      "[59,  2000]\n",
      "[59,  2200]\n",
      "[59,  2400]\n",
      "[59,  2600]\n",
      "[59,  2800]\n",
      "58 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[59,   200]\n",
      "[59,   400]\n",
      "[59,   600]\n",
      "[59,   800]\n",
      "[59,  1000]\n",
      "[59,  1200]\n",
      "[59,  1400]\n",
      "[59,  1600]\n",
      "[59,  1800]\n",
      "[59,  2000]\n",
      "[59,  2200]\n",
      "[59,  2400]\n",
      "[59,  2600]\n",
      "[59,  2800]\n",
      "58 Epoch val Loss: 0.0354 Acc: 0.7027\n",
      "[60,   200]\n",
      "[60,   400]\n",
      "[60,   600]\n",
      "[60,   800]\n",
      "[60,  1000]\n",
      "[60,  1200]\n",
      "[60,  1400]\n",
      "[60,  1600]\n",
      "[60,  1800]\n",
      "[60,  2000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60,  2200]\n",
      "[60,  2400]\n",
      "[60,  2600]\n",
      "[60,  2800]\n",
      "59 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[60,   200]\n",
      "[60,   400]\n",
      "[60,   600]\n",
      "[60,   800]\n",
      "[60,  1000]\n",
      "[60,  1200]\n",
      "[60,  1400]\n",
      "[60,  1600]\n",
      "[60,  1800]\n",
      "[60,  2000]\n",
      "[60,  2200]\n",
      "[60,  2400]\n",
      "[60,  2600]\n",
      "[60,  2800]\n",
      "59 Epoch val Loss: 0.0354 Acc: 0.7024\n",
      "[61,   200]\n",
      "[61,   400]\n",
      "[61,   600]\n",
      "[61,   800]\n",
      "[61,  1000]\n",
      "[61,  1200]\n",
      "[61,  1400]\n",
      "[61,  1600]\n",
      "[61,  1800]\n",
      "[61,  2000]\n",
      "[61,  2200]\n",
      "[61,  2400]\n",
      "[61,  2600]\n",
      "[61,  2800]\n",
      "60 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[61,   200]\n",
      "[61,   400]\n",
      "[61,   600]\n",
      "[61,   800]\n",
      "[61,  1000]\n",
      "[61,  1200]\n",
      "[61,  1400]\n",
      "[61,  1600]\n",
      "[61,  1800]\n",
      "[61,  2000]\n",
      "[61,  2200]\n",
      "[61,  2400]\n",
      "[61,  2600]\n",
      "[61,  2800]\n",
      "60 Epoch val Loss: 0.0359 Acc: 0.7008\n",
      "[62,   200]\n",
      "[62,   400]\n",
      "[62,   600]\n",
      "[62,   800]\n",
      "[62,  1000]\n",
      "[62,  1200]\n",
      "[62,  1400]\n",
      "[62,  1600]\n",
      "[62,  1800]\n",
      "[62,  2000]\n",
      "[62,  2200]\n",
      "[62,  2400]\n",
      "[62,  2600]\n",
      "[62,  2800]\n",
      "61 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[62,   200]\n",
      "[62,   400]\n",
      "[62,   600]\n",
      "[62,   800]\n",
      "[62,  1000]\n",
      "[62,  1200]\n",
      "[62,  1400]\n",
      "[62,  1600]\n",
      "[62,  1800]\n",
      "[62,  2000]\n",
      "[62,  2200]\n",
      "[62,  2400]\n",
      "[62,  2600]\n",
      "[62,  2800]\n",
      "61 Epoch val Loss: 0.0354 Acc: 0.7024\n",
      "[63,   200]\n",
      "[63,   400]\n",
      "[63,   600]\n",
      "[63,   800]\n",
      "[63,  1000]\n",
      "[63,  1200]\n",
      "[63,  1400]\n",
      "[63,  1600]\n",
      "[63,  1800]\n",
      "[63,  2000]\n",
      "[63,  2200]\n",
      "[63,  2400]\n",
      "[63,  2600]\n",
      "[63,  2800]\n",
      "62 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[63,   200]\n",
      "[63,   400]\n",
      "[63,   600]\n",
      "[63,   800]\n",
      "[63,  1000]\n",
      "[63,  1200]\n",
      "[63,  1400]\n",
      "[63,  1600]\n",
      "[63,  1800]\n",
      "[63,  2000]\n",
      "[63,  2200]\n",
      "[63,  2400]\n",
      "[63,  2600]\n",
      "[63,  2800]\n",
      "62 Epoch val Loss: 0.0355 Acc: 0.7022\n",
      "[64,   200]\n",
      "[64,   400]\n",
      "[64,   600]\n",
      "[64,   800]\n",
      "[64,  1000]\n",
      "[64,  1200]\n",
      "[64,  1400]\n",
      "[64,  1600]\n",
      "[64,  1800]\n",
      "[64,  2000]\n",
      "[64,  2200]\n",
      "[64,  2400]\n",
      "[64,  2600]\n",
      "[64,  2800]\n",
      "63 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[64,   200]\n",
      "[64,   400]\n",
      "[64,   600]\n",
      "[64,   800]\n",
      "[64,  1000]\n",
      "[64,  1200]\n",
      "[64,  1400]\n",
      "[64,  1600]\n",
      "[64,  1800]\n",
      "[64,  2000]\n",
      "[64,  2200]\n",
      "[64,  2400]\n",
      "[64,  2600]\n",
      "[64,  2800]\n",
      "63 Epoch val Loss: 0.0355 Acc: 0.7027\n",
      "[65,   200]\n",
      "[65,   400]\n",
      "[65,   600]\n",
      "[65,   800]\n",
      "[65,  1000]\n",
      "[65,  1200]\n",
      "[65,  1400]\n",
      "[65,  1600]\n",
      "[65,  1800]\n",
      "[65,  2000]\n",
      "[65,  2200]\n",
      "[65,  2400]\n",
      "[65,  2600]\n",
      "[65,  2800]\n",
      "64 Epoch train Loss: 0.0004 Acc: 0.9996\n",
      "[65,   200]\n",
      "[65,   400]\n",
      "[65,   600]\n",
      "[65,   800]\n",
      "[65,  1000]\n",
      "[65,  1200]\n",
      "[65,  1400]\n",
      "[65,  1600]\n",
      "[65,  1800]\n",
      "[65,  2000]\n",
      "[65,  2200]\n",
      "[65,  2400]\n",
      "[65,  2600]\n",
      "[65,  2800]\n",
      "64 Epoch val Loss: 0.0355 Acc: 0.7034\n",
      "[66,   200]\n",
      "[66,   400]\n",
      "[66,   600]\n",
      "[66,   800]\n",
      "[66,  1000]\n",
      "[66,  1200]\n",
      "[66,  1400]\n",
      "[66,  1600]\n",
      "[66,  1800]\n",
      "[66,  2000]\n",
      "[66,  2200]\n",
      "[66,  2400]\n",
      "[66,  2600]\n",
      "[66,  2800]\n",
      "65 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[66,   200]\n",
      "[66,   400]\n",
      "[66,   600]\n",
      "[66,   800]\n",
      "[66,  1000]\n",
      "[66,  1200]\n",
      "[66,  1400]\n",
      "[66,  1600]\n",
      "[66,  1800]\n",
      "[66,  2000]\n",
      "[66,  2200]\n",
      "[66,  2400]\n",
      "[66,  2600]\n",
      "[66,  2800]\n",
      "65 Epoch val Loss: 0.0354 Acc: 0.7041\n",
      "[67,   200]\n",
      "[67,   400]\n",
      "[67,   600]\n",
      "[67,   800]\n",
      "[67,  1000]\n",
      "[67,  1200]\n",
      "[67,  1400]\n",
      "[67,  1600]\n",
      "[67,  1800]\n",
      "[67,  2000]\n",
      "[67,  2200]\n",
      "[67,  2400]\n",
      "[67,  2600]\n",
      "[67,  2800]\n",
      "66 Epoch train Loss: 0.0004 Acc: 0.9995\n",
      "[67,   200]\n",
      "[67,   400]\n",
      "[67,   600]\n",
      "[67,   800]\n",
      "[67,  1000]\n",
      "[67,  1200]\n",
      "[67,  1400]\n",
      "[67,  1600]\n",
      "[67,  1800]\n",
      "[67,  2000]\n",
      "[67,  2200]\n",
      "[67,  2400]\n",
      "[67,  2600]\n",
      "[67,  2800]\n",
      "66 Epoch val Loss: 0.0359 Acc: 0.7039\n",
      "[68,   200]\n",
      "[68,   400]\n",
      "[68,   600]\n",
      "[68,   800]\n",
      "[68,  1000]\n",
      "[68,  1200]\n",
      "[68,  1400]\n",
      "[68,  1600]\n",
      "[68,  1800]\n",
      "[68,  2000]\n",
      "[68,  2200]\n",
      "[68,  2400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-285:\n",
      "Process Process-286:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/transforms/transforms.py\", line 215, in __call__\n",
      "    return F.center_crop(img, self.size)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/transforms/functional.py\", line 305, in center_crop\n",
      "    w, h = img.size\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 920, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-fbcd8a0bbdb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# if the model predicts the same results as the true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# label, then the correct counter will plus 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "best_model = model\n",
    "best_acc = 0.0\n",
    "val_acc = 0.0\n",
    "print(device)\n",
    "\n",
    "model.train()\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, verbose=True)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma=0.5)\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "        \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train(True)  # Set model to training mode\n",
    "            dset_loaders = trainloader\n",
    "        else:\n",
    "            model.train(False)  # Set model to evaluate mode\n",
    "            dset_loaders = valloader\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        \n",
    "        for i, data in enumerate(dset_loaders, 0):\n",
    "        \n",
    "            (inputs, labels) = data\n",
    "            \n",
    "            #change the type into cuda tensor \n",
    "            if device == 'cuda':\n",
    "                inputs = inputs.cuda(0)\n",
    "                labels = labels.cuda(0)\n",
    "            else:\n",
    "                inputs = inputs.cpu()\n",
    "                labels = labels.cpu()\n",
    "\n",
    "            #print(labels)\n",
    "            #print(inputs)\n",
    "        \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            # select the class with highest probability\n",
    "            _, pred = outputs.max(1)\n",
    "            # if the model predicts the same results as the true\n",
    "            # label, then the correct counter will plus 1\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "        \n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if (i % 200) == 199:    # print every 200 mini-batches\n",
    "                print('[%d, %5d]' % (epoch + 1, i + 1))\n",
    "            \n",
    "        if phase == 'train':\n",
    "            epoch_loss = running_loss / len(trainset)\n",
    "            epoch_acc = correct / len(trainset)\n",
    "        else:\n",
    "            epoch_loss = running_loss / len(valset)\n",
    "            epoch_acc = correct / len(valset)\n",
    "            val_acc = epoch_acc\n",
    "\n",
    "        print('{:d} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(epoch, phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(best_model, './model.pt')\n",
    "    lr_scheduler.step(val_acc)\n",
    "print('Finished Training')\n",
    "\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Saving model..\n",
      "Finished Saving\n"
     ]
    }
   ],
   "source": [
    "print('==> Saving model..')\n",
    "\n",
    "#only save model parameters\n",
    "torch.save(model.state_dict(), './checkpoint.t7')\n",
    "#you also can store some log information\n",
    "state = {\n",
    "    'net': model.state_dict(),\n",
    "    'acc': 100.*correct/len(trainset),\n",
    "    'epoch': epoch\n",
    "}\n",
    "torch.save(state, './checkpoint.t7')\n",
    "\n",
    "#save entire model\n",
    "torch.save(model, './model.pt')\n",
    "\n",
    "print('Finished Saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Testing model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('==> Testing model..')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  200]\n",
      "[  400]\n",
      "[  600]\n",
      "[  800]\n",
      "[ 1000]\n",
      "[ 1200]\n",
      "[ 1400]\n",
      "[ 1600]\n",
      "[ 1800]\n",
      "[ 2000]\n",
      "[ 2200]\n",
      "[ 2400]\n",
      "[ 2600]\n",
      "[ 2800]\n",
      "Accuracy of the network on the 90000 test images: 70.05%, and loss is: 0.036\n",
      "Accuracy of airplane : 81 %\n",
      "Accuracy of automobile : 75 %\n",
      "Accuracy of  bird : 62 %\n",
      "Accuracy of   cat : 57 %\n",
      "Accuracy of  deer : 60 %\n",
      "Accuracy of   dog : 53 %\n",
      "Accuracy of  frog : 82 %\n",
      "Accuracy of horse : 75 %\n",
      "Accuracy of  ship : 78 %\n",
      "Accuracy of truck : 73 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "running_loss = 0.0\n",
    "# device == 'cpu'\n",
    "class_correct = list(0. for i in range(11))\n",
    "class_total = list(0. for i in range(11))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mini_batch, data in enumerate(testloader, 0):\n",
    "        images, labels = data\n",
    "\n",
    "        if device == 'cuda':\n",
    "            images = images.cuda(0)\n",
    "            labels = labels.cuda(0)\n",
    "        else:\n",
    "            images = images.cpu()\n",
    "            labels = labels.cpu()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        c = (predicted == labels).squeeze()\n",
    "        #print(predicted)\n",
    "        #print(labels.size(0))\n",
    "        #print(c)\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "        if(mini_batch % 200 == 199):\n",
    "            print('[%5d]' % (mini_batch + 1))\n",
    "            \n",
    "print('Accuracy of the network on the %d test images: %.2f%%, and loss is: %.3f'\n",
    "      % (total, 100 * correct / total, running_loss / total))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
